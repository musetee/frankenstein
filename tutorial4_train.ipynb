{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zy7\\AppData\\Roaming\\Python\\Python38\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anish\n",
      "anish_seg\n",
      "multimodal_csv\n",
      "multimodal_prior_csv\n",
      "combined_simplified_csv_seg_assigned\n",
      "combined_simplified_csv_seg_without_assigned_loader\n",
      "combined_simplified_csv_seg_mr_loader\n",
      "mr2ct_simplified_csv\n",
      "xcat_ct_simplified_csv\n",
      "synthetic_ct_simplified_csv\n",
      "synthrad_mr2ct\n",
      "synthrad_seg\n",
      "combined\n",
      "combined_assigned\n",
      "csv_slice\n",
      "csv_slice_assigned\n",
      "json_slice\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import sys\n",
    "sys.path.append('./dataprocesser')\n",
    "from synthrad_conversion.utils.my_configs_yacs import init_cfg\n",
    "from dataprocesser.step1_init_data_list import init_dataset\n",
    "import dataprocesser\n",
    "from dataprocesser.dataset_registry import DATASET_REGISTRY\n",
    "\n",
    "for dataset_type in DATASET_REGISTRY:\n",
    "    print(dataset_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infer_ddpm2d_seg2med_multimodal\n",
      "create combined segmentation dataset with assigned value\n",
      "create base dataset\n",
      "combined segmentation assigned dataset use keys: ['source', 'target']\n",
      "use train csv: tutorial2_train_prior.csv\n",
      "use test csv: tutorial2_val_prior_1.csv\n",
      "use keys for creating volume dataset:  ['source', 'target']\n",
      "model name:  ddpm2d_seg2med_multimodal\n",
      "val_use_patch:  False\n",
      "527\n",
      "4\n",
      "original image shape: torch.Size([1, 1, 512, 512, 39])\n",
      "original image min and max: 0.0 1.0\n",
      "original image modality: tensor([4])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from synthrad_conversion.utils.my_configs_yacs import init_cfg\n",
    "from dataprocesser.step1_init_data_list import init_dataset\n",
    "config_path = 'tutorial2_config_prior.yaml'\n",
    "opt=init_cfg(config_path)\n",
    "model_name_path='Infer_'+opt.model_name + opt.name_prefix\n",
    "print(model_name_path)\n",
    "dataset_name = 'multimodal_prior_csv'\n",
    "loader, opt, my_paths = init_dataset(opt, model_name_path, dataset_name)\n",
    "\n",
    "train_ds = loader.train_ds\n",
    "val_ds  = loader.val_ds\n",
    "print(len(train_ds))\n",
    "print(len(val_ds))\n",
    "\n",
    "train_loader = loader.train_loader\n",
    "val_loader  = loader.val_loader\n",
    "first_batch = next(iter(val_loader))\n",
    "first_input = first_batch[opt.dataset.indicator_A]\n",
    "first_target = first_batch[opt.dataset.indicator_B]\n",
    "print(\"original image shape:\", first_target.shape)\n",
    "print(\"original image min and max:\", np.min(first_target), np.max(first_target))\n",
    "print(\"original image modality:\", first_batch['modality'])\n",
    "\n",
    "\n",
    "# visualize a slice:\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "def plottorchdata(data, i, slice_id):\n",
    "    data = data.cpu().numpy().squeeze().squeeze()\n",
    "    dataimg = f'tutorial_{i}.png'\n",
    "    plt.figure(i)\n",
    "    plt.imshow(data[..., slice_id].T, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    #plt.savefig(dataimg)\n",
    "slice_id = 10\n",
    "plottorchdata(first_input, 0, slice_id)\n",
    "plottorchdata(first_target, 1, slice_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: wandb package cannot be found. The option \"--use_wandb\" will result in error.\n",
      "Warning: wandb package cannot be found. The option \"--use_wandb\" will result in error.\n",
      "ddpm2d_seg2med\n",
      "ddpm2d_seg2med_multimodal\n",
      "spade_ddpm2d_seg2med\n",
      "pix2pix\n",
      "cycle_gan\n",
      "AttentionUnet\n",
      "resUnet\n"
     ]
    }
   ],
   "source": [
    "import synthrad_conversion.networks as networks\n",
    "from synthrad_conversion.networks.model_registry import MODEL_REGISTRY\n",
    "for model in MODEL_REGISTRY:\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zy7\\AppData\\Roaming\\Python\\Python38\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: wandb package cannot be found. The option \"--use_wandb\" will result in error.\n",
      "Warning: wandb package cannot be found. The option \"--use_wandb\" will result in error.\n",
      "create combined segmentation dataset with assigned value\n",
      "create base dataset\n",
      "combined segmentation assigned dataset use keys: ['source', 'target']\n",
      "use train csv: tutorial2_train_prior.csv\n",
      "use test csv: tutorial2_val_prior_1.csv\n",
      "use keys for creating volume dataset:  ['source', 'target']\n",
      "model name:  ddpm2d_seg2med_multimodal\n",
      "val_use_patch:  False\n",
      "given GPU IDs:  [1]\n",
      "use GPU:  NVIDIA RTX A6000\n",
      "no valid checkpoint as input, start new training\n",
      "early stopping criterion on, set patience as 10, convergence rate as 0.1%\n",
      "original image shape: torch.Size([1, 1, 512, 512, 149])\n",
      "training: [1/527] Processing volume...\n",
      "\n",
      " first input volume shape: torch.Size([1, 512, 512, 149])\n",
      "first target volume shape: torch.Size([1, 512, 512, 149])\n",
      "first patient ID: 1PA004\n",
      "first ad: tensor(0)\n",
      "first modality: tensor(0)\n",
      "\n",
      " input shape: torch.Size([1, 512, 512, 149])\n",
      "sources, min,max,mean,std:  metatensor(0.) metatensor(1.) metatensor(0.0686) metatensor(0.1514)\n",
      "targets, min,max,mean,std:  metatensor(0.) metatensor(1.) metatensor(0.0635) metatensor(0.1319)\n",
      "training: [2/527] Processing volume...\n",
      "training: [3/527] Processing volume...\n",
      "training: [4/527] Processing volume...\n",
      "training: [5/527] Processing volume...\n",
      "training: [6/527] Processing volume...\n",
      "training: [7/527] Processing volume...\n",
      "training: [8/527] Processing volume...\n",
      "training: [9/527] Processing volume...\n",
      "training: [10/527] Processing volume...\n",
      "training: [11/527] Processing volume...\n",
      "training: [12/527] Processing volume...\n",
      "training: [13/527] Processing volume...\n",
      "training: [14/527] Processing volume...\n",
      "training: [15/527] Processing volume...\n",
      "training: [16/527] Processing volume...\n",
      "training: [17/527] Processing volume...\n",
      "training: [18/527] Processing volume...\n",
      "training: [19/527] Processing volume...\n",
      "training: [20/527] Processing volume...\n",
      "training: [21/527] Processing volume...\n",
      "training: [22/527] Processing volume...\n",
      "training: [23/527] Processing volume...\n",
      "training: [24/527] Processing volume...\n",
      "training: [25/527] Processing volume...\n",
      "training: [26/527] Processing volume...\n",
      "training: [27/527] Processing volume...\n",
      "training: [28/527] Processing volume...\n",
      "training: [29/527] Processing volume...\n",
      "training: [30/527] Processing volume...\n",
      "training: [31/527] Processing volume...\n",
      "training: [32/527] Processing volume...\n",
      "training: [33/527] Processing volume...\n",
      "training: [34/527] Processing volume...\n",
      "validation step in training epoch 1\n",
      "aorta dissection not manually set, use the value in csv file\n",
      "original image shape: torch.Size([1, 1, 512, 512, 89])\n",
      "inference val set from 10 to 10 batch\n",
      "validation: [1/2] Processing volume...\n",
      "patient ID: 1PC078\n",
      "input volume shape: torch.Size([1, 512, 512, 89])\n",
      "target volume shape: torch.Size([1, 512, 512, 89])\n",
      "ad: tensor(0)\n",
      "modality: tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 12.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: [2/2] Processing volume...\n",
      "patient ID: 42025705_4\n",
      "input volume shape: torch.Size([1, 512, 512, 39])\n",
      "target volume shape: torch.Size([1, 512, 512, 39])\n",
      "ad: tensor(0)\n",
      "modality: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: [35/527] Processing volume...\n",
      "training: [36/527] Processing volume...\n",
      "training: [37/527] Processing volume...\n",
      "training: [38/527] Processing volume...\n",
      "training: [39/527] Processing volume...\n",
      "training: [40/527] Processing volume...\n",
      "training: [41/527] Processing volume...\n",
      "training: [42/527] Processing volume...\n",
      "training: [43/527] Processing volume...\n",
      "training: [44/527] Processing volume...\n",
      "training: [45/527] Processing volume...\n",
      "training: [46/527] Processing volume...\n",
      "training: [47/527] Processing volume...\n",
      "training: [48/527] Processing volume...\n",
      "training: [49/527] Processing volume...\n",
      "training: [50/527] Processing volume...\n",
      "training: [51/527] Processing volume...\n",
      "training: [52/527] Processing volume...\n",
      "training: [53/527] Processing volume...\n",
      "training: [54/527] Processing volume...\n",
      "training: [55/527] Processing volume...\n",
      "training: [56/527] Processing volume...\n",
      "training: [57/527] Processing volume...\n",
      "training: [58/527] Processing volume...\n",
      "training: [59/527] Processing volume...\n",
      "training: [60/527] Processing volume...\n",
      "training: [61/527] Processing volume...\n",
      "training: [62/527] Processing volume...\n",
      "training: [63/527] Processing volume...\n",
      "training: [64/527] Processing volume...\n",
      "training: [65/527] Processing volume...\n",
      "training: [66/527] Processing volume...\n",
      "training: [67/527] Processing volume...\n",
      "validation step in training epoch 1\n",
      "aorta dissection not manually set, use the value in csv file\n",
      "original image shape: torch.Size([1, 1, 512, 512, 89])\n",
      "inference val set from 10 to 10 batch\n",
      "validation: [1/2] Processing volume...\n",
      "patient ID: 1PC078\n",
      "input volume shape: torch.Size([1, 512, 512, 89])\n",
      "target volume shape: torch.Size([1, 512, 512, 89])\n",
      "ad: tensor(0)\n",
      "modality: tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: [2/2] Processing volume...\n",
      "patient ID: 42025705_4\n",
      "input volume shape: torch.Size([1, 512, 512, 39])\n",
      "target volume shape: torch.Size([1, 512, 512, 39])\n",
      "ad: tensor(0)\n",
      "modality: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: [68/527] Processing volume...\n",
      "training: [69/527] Processing volume...\n",
      "training: [70/527] Processing volume...\n",
      "training: [71/527] Processing volume...\n",
      "training: [72/527] Processing volume...\n",
      "training: [73/527] Processing volume...\n",
      "training: [74/527] Processing volume...\n",
      "training: [75/527] Processing volume...\n",
      "training: [76/527] Processing volume...\n",
      "training: [77/527] Processing volume...\n",
      "training: [78/527] Processing volume...\n",
      "training: [79/527] Processing volume...\n",
      "training: [80/527] Processing volume...\n",
      "training: [81/527] Processing volume...\n",
      "training: [82/527] Processing volume...\n",
      "training: [83/527] Processing volume...\n",
      "training: [84/527] Processing volume...\n",
      "training: [85/527] Processing volume...\n",
      "training: [86/527] Processing volume...\n",
      "training: [87/527] Processing volume...\n",
      "training: [88/527] Processing volume...\n",
      "training: [89/527] Processing volume...\n",
      "training: [90/527] Processing volume...\n",
      "training: [91/527] Processing volume...\n",
      "training: [92/527] Processing volume...\n",
      "training: [93/527] Processing volume...\n",
      "training: [94/527] Processing volume...\n",
      "training: [95/527] Processing volume...\n",
      "training: [96/527] Processing volume...\n",
      "training: [97/527] Processing volume...\n",
      "training: [98/527] Processing volume...\n",
      "training: [99/527] Processing volume...\n",
      "training: [100/527] Processing volume...\n",
      "training: [101/527] Processing volume...\n",
      "validation step in training epoch 1\n",
      "aorta dissection not manually set, use the value in csv file\n",
      "original image shape: torch.Size([1, 1, 512, 512, 89])\n",
      "inference val set from 10 to 10 batch\n",
      "validation: [1/2] Processing volume...\n",
      "patient ID: 1PC078\n",
      "input volume shape: torch.Size([1, 512, 512, 89])\n",
      "target volume shape: torch.Size([1, 512, 512, 89])\n",
      "ad: tensor(0)\n",
      "modality: tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: [2/2] Processing volume...\n",
      "patient ID: 42025705_4\n",
      "input volume shape: torch.Size([1, 512, 512, 39])\n",
      "target volume shape: torch.Size([1, 512, 512, 39])\n",
      "ad: tensor(0)\n",
      "modality: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: [102/527] Processing volume...\n",
      "training: [103/527] Processing volume...\n",
      "training: [104/527] Processing volume...\n",
      "training: [105/527] Processing volume...\n",
      "training: [106/527] Processing volume...\n",
      "training: [107/527] Processing volume...\n",
      "training: [108/527] Processing volume...\n",
      "training: [109/527] Processing volume...\n",
      "training: [110/527] Processing volume...\n",
      "training: [111/527] Processing volume...\n",
      "training: [112/527] Processing volume...\n",
      "training: [113/527] Processing volume...\n",
      "training: [114/527] Processing volume...\n",
      "training: [115/527] Processing volume...\n",
      "training: [116/527] Processing volume...\n",
      "training: [117/527] Processing volume...\n",
      "training: [118/527] Processing volume...\n",
      "training: [119/527] Processing volume...\n",
      "training: [120/527] Processing volume...\n",
      "training: [121/527] Processing volume...\n",
      "training: [122/527] Processing volume...\n",
      "training: [123/527] Processing volume...\n",
      "training: [124/527] Processing volume...\n",
      "training: [125/527] Processing volume...\n",
      "training: [126/527] Processing volume...\n",
      "training: [127/527] Processing volume...\n",
      "training: [128/527] Processing volume...\n",
      "training: [129/527] Processing volume...\n",
      "training: [130/527] Processing volume...\n",
      "training: [131/527] Processing volume...\n",
      "training: [132/527] Processing volume...\n",
      "training: [133/527] Processing volume...\n",
      "training: [134/527] Processing volume...\n",
      "training: [135/527] Processing volume...\n",
      "validation step in training epoch 1\n",
      "aorta dissection not manually set, use the value in csv file\n",
      "original image shape: torch.Size([1, 1, 512, 512, 89])\n",
      "inference val set from 10 to 10 batch\n",
      "validation: [1/2] Processing volume...\n",
      "patient ID: 1PC078\n",
      "input volume shape: torch.Size([1, 512, 512, 89])\n",
      "target volume shape: torch.Size([1, 512, 512, 89])\n",
      "ad: tensor(0)\n",
      "modality: tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: [2/2] Processing volume...\n",
      "patient ID: 42025705_4\n",
      "input volume shape: torch.Size([1, 512, 512, 39])\n",
      "target volume shape: torch.Size([1, 512, 512, 39])\n",
      "ad: tensor(0)\n",
      "modality: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: [136/527] Processing volume...\n",
      "training: [137/527] Processing volume...\n",
      "training: [138/527] Processing volume...\n",
      "training: [139/527] Processing volume...\n",
      "training: [140/527] Processing volume...\n",
      "training: [141/527] Processing volume...\n",
      "training: [142/527] Processing volume...\n",
      "training: [143/527] Processing volume...\n",
      "training: [144/527] Processing volume...\n",
      "training: [145/527] Processing volume...\n",
      "training: [146/527] Processing volume...\n",
      "training: [147/527] Processing volume...\n",
      "training: [148/527] Processing volume...\n",
      "training: [149/527] Processing volume...\n",
      "training: [150/527] Processing volume...\n",
      "training: [151/527] Processing volume...\n",
      "training: [152/527] Processing volume...\n",
      "training: [153/527] Processing volume...\n",
      "training: [154/527] Processing volume...\n",
      "training: [155/527] Processing volume...\n",
      "training: [156/527] Processing volume...\n",
      "training: [157/527] Processing volume...\n",
      "training: [158/527] Processing volume...\n",
      "training: [159/527] Processing volume...\n",
      "training: [160/527] Processing volume...\n",
      "training: [161/527] Processing volume...\n",
      "training: [162/527] Processing volume...\n",
      "training: [163/527] Processing volume...\n",
      "training: [164/527] Processing volume...\n",
      "training: [165/527] Processing volume...\n",
      "training: [166/527] Processing volume...\n",
      "training: [167/527] Processing volume...\n",
      "validation step in training epoch 1\n",
      "aorta dissection not manually set, use the value in csv file\n",
      "original image shape: torch.Size([1, 1, 512, 512, 89])\n",
      "inference val set from 10 to 10 batch\n",
      "validation: [1/2] Processing volume...\n",
      "patient ID: 1PC078\n",
      "input volume shape: torch.Size([1, 512, 512, 89])\n",
      "target volume shape: torch.Size([1, 512, 512, 89])\n",
      "ad: tensor(0)\n",
      "modality: tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: [2/2] Processing volume...\n",
      "patient ID: 42025705_4\n",
      "input volume shape: torch.Size([1, 512, 512, 39])\n",
      "target volume shape: torch.Size([1, 512, 512, 39])\n",
      "ad: tensor(0)\n",
      "modality: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: [168/527] Processing volume...\n",
      "training: [169/527] Processing volume...\n",
      "training: [170/527] Processing volume...\n",
      "training: [171/527] Processing volume...\n",
      "training: [172/527] Processing volume...\n",
      "training: [173/527] Processing volume...\n",
      "training: [174/527] Processing volume...\n",
      "training: [175/527] Processing volume...\n",
      "training: [176/527] Processing volume...\n",
      "training: [177/527] Processing volume...\n",
      "training: [178/527] Processing volume...\n",
      "training: [179/527] Processing volume...\n",
      "training: [180/527] Processing volume...\n",
      "training: [181/527] Processing volume...\n",
      "training: [182/527] Processing volume...\n",
      "training: [183/527] Processing volume...\n",
      "training: [184/527] Processing volume...\n",
      "training: [185/527] Processing volume...\n",
      "training: [186/527] Processing volume...\n",
      "training: [187/527] Processing volume...\n",
      "training: [188/527] Processing volume...\n",
      "training: [189/527] Processing volume...\n",
      "training: [190/527] Processing volume...\n",
      "training: [191/527] Processing volume...\n",
      "training: [192/527] Processing volume...\n",
      "training: [193/527] Processing volume...\n",
      "training: [194/527] Processing volume...\n",
      "training: [195/527] Processing volume...\n",
      "training: [196/527] Processing volume...\n",
      "training: [197/527] Processing volume...\n",
      "training: [198/527] Processing volume...\n",
      "validation step in training epoch 1\n",
      "aorta dissection not manually set, use the value in csv file\n",
      "original image shape: torch.Size([1, 1, 512, 512, 89])\n",
      "inference val set from 10 to 10 batch\n",
      "validation: [1/2] Processing volume...\n",
      "patient ID: 1PC078\n",
      "input volume shape: torch.Size([1, 512, 512, 89])\n",
      "target volume shape: torch.Size([1, 512, 512, 89])\n",
      "ad: tensor(0)\n",
      "modality: tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: [2/2] Processing volume...\n",
      "patient ID: 42025705_4\n",
      "input volume shape: torch.Size([1, 512, 512, 39])\n",
      "target volume shape: torch.Size([1, 512, 512, 39])\n",
      "ad: tensor(0)\n",
      "modality: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: [199/527] Processing volume...\n",
      "training: [200/527] Processing volume...\n",
      "training: [201/527] Processing volume...\n",
      "training: [202/527] Processing volume...\n",
      "training: [203/527] Processing volume...\n",
      "training: [204/527] Processing volume...\n",
      "training: [205/527] Processing volume...\n",
      "training: [206/527] Processing volume...\n",
      "training: [207/527] Processing volume...\n",
      "training: [208/527] Processing volume...\n",
      "training: [209/527] Processing volume...\n",
      "training: [210/527] Processing volume...\n",
      "training: [211/527] Processing volume...\n",
      "training: [212/527] Processing volume...\n",
      "training: [213/527] Processing volume...\n",
      "training: [214/527] Processing volume...\n",
      "training: [215/527] Processing volume...\n",
      "training: [216/527] Processing volume...\n",
      "training: [217/527] Processing volume...\n",
      "training: [218/527] Processing volume...\n",
      "training: [219/527] Processing volume...\n",
      "training: [220/527] Processing volume...\n",
      "training: [221/527] Processing volume...\n",
      "training: [222/527] Processing volume...\n",
      "training: [223/527] Processing volume...\n",
      "training: [224/527] Processing volume...\n",
      "training: [225/527] Processing volume...\n",
      "training: [226/527] Processing volume...\n",
      "training: [227/527] Processing volume...\n",
      "training: [228/527] Processing volume...\n",
      "validation step in training epoch 1\n",
      "aorta dissection not manually set, use the value in csv file\n",
      "original image shape: torch.Size([1, 1, 512, 512, 89])\n",
      "inference val set from 10 to 10 batch\n",
      "validation: [1/2] Processing volume...\n",
      "patient ID: 1PC078\n",
      "input volume shape: torch.Size([1, 512, 512, 89])\n",
      "target volume shape: torch.Size([1, 512, 512, 89])\n",
      "ad: tensor(0)\n",
      "modality: tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: [2/2] Processing volume...\n",
      "patient ID: 42025705_4\n",
      "input volume shape: torch.Size([1, 512, 512, 39])\n",
      "target volume shape: torch.Size([1, 512, 512, 39])\n",
      "ad: tensor(0)\n",
      "modality: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: [229/527] Processing volume...\n",
      "training: [230/527] Processing volume...\n",
      "training: [231/527] Processing volume...\n",
      "training: [232/527] Processing volume...\n",
      "training: [233/527] Processing volume...\n",
      "training: [234/527] Processing volume...\n",
      "training: [235/527] Processing volume...\n",
      "training: [236/527] Processing volume...\n",
      "training: [237/527] Processing volume...\n",
      "training: [238/527] Processing volume...\n",
      "training: [239/527] Processing volume...\n",
      "training: [240/527] Processing volume...\n",
      "training: [241/527] Processing volume...\n",
      "training: [242/527] Processing volume...\n",
      "training: [243/527] Processing volume...\n",
      "training: [244/527] Processing volume...\n",
      "training: [245/527] Processing volume...\n",
      "training: [246/527] Processing volume...\n",
      "training: [247/527] Processing volume...\n",
      "training: [248/527] Processing volume...\n",
      "training: [249/527] Processing volume...\n",
      "training: [250/527] Processing volume...\n",
      "training: [251/527] Processing volume...\n",
      "training: [252/527] Processing volume...\n",
      "training: [253/527] Processing volume...\n",
      "training: [254/527] Processing volume...\n",
      "training: [255/527] Processing volume...\n",
      "training: [256/527] Processing volume...\n",
      "training: [257/527] Processing volume...\n",
      "training: [258/527] Processing volume...\n",
      "training: [259/527] Processing volume...\n",
      "training: [260/527] Processing volume...\n",
      "training: [261/527] Processing volume...\n",
      "training: [262/527] Processing volume...\n",
      "training: [263/527] Processing volume...\n",
      "training: [264/527] Processing volume...\n",
      "training: [265/527] Processing volume...\n",
      "training: [266/527] Processing volume...\n",
      "training: [267/527] Processing volume...\n",
      "validation step in training epoch 1\n",
      "aorta dissection not manually set, use the value in csv file\n",
      "original image shape: torch.Size([1, 1, 512, 512, 89])\n",
      "inference val set from 10 to 10 batch\n",
      "validation: [1/2] Processing volume...\n",
      "patient ID: 1PC078\n",
      "input volume shape: torch.Size([1, 512, 512, 89])\n",
      "target volume shape: torch.Size([1, 512, 512, 89])\n",
      "ad: tensor(0)\n",
      "modality: tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: [2/2] Processing volume...\n",
      "patient ID: 42025705_4\n",
      "input volume shape: torch.Size([1, 512, 512, 39])\n",
      "target volume shape: torch.Size([1, 512, 512, 39])\n",
      "ad: tensor(0)\n",
      "modality: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: [268/527] Processing volume...\n",
      "training: [269/527] Processing volume...\n",
      "training: [270/527] Processing volume...\n",
      "training: [271/527] Processing volume...\n",
      "training: [272/527] Processing volume...\n",
      "training: [273/527] Processing volume...\n",
      "training: [274/527] Processing volume...\n",
      "training: [275/527] Processing volume...\n",
      "training: [276/527] Processing volume...\n",
      "training: [277/527] Processing volume...\n",
      "training: [278/527] Processing volume...\n",
      "training: [279/527] Processing volume...\n",
      "training: [280/527] Processing volume...\n",
      "training: [281/527] Processing volume...\n",
      "training: [282/527] Processing volume...\n",
      "training: [283/527] Processing volume...\n",
      "training: [284/527] Processing volume...\n",
      "training: [285/527] Processing volume...\n",
      "training: [286/527] Processing volume...\n",
      "training: [287/527] Processing volume...\n",
      "training: [288/527] Processing volume...\n",
      "training: [289/527] Processing volume...\n",
      "training: [290/527] Processing volume...\n",
      "training: [291/527] Processing volume...\n",
      "training: [292/527] Processing volume...\n",
      "training: [293/527] Processing volume...\n",
      "training: [294/527] Processing volume...\n",
      "training: [295/527] Processing volume...\n",
      "training: [296/527] Processing volume...\n",
      "training: [297/527] Processing volume...\n",
      "training: [298/527] Processing volume...\n",
      "training: [299/527] Processing volume...\n",
      "training: [300/527] Processing volume...\n",
      "training: [301/527] Processing volume...\n",
      "training: [302/527] Processing volume...\n",
      "training: [303/527] Processing volume...\n",
      "training: [304/527] Processing volume...\n",
      "training: [305/527] Processing volume...\n",
      "training: [306/527] Processing volume...\n",
      "training: [307/527] Processing volume...\n",
      "training: [308/527] Processing volume...\n",
      "training: [309/527] Processing volume...\n",
      "training: [310/527] Processing volume...\n",
      "training: [311/527] Processing volume...\n",
      "training: [312/527] Processing volume...\n",
      "training: [313/527] Processing volume...\n",
      "training: [314/527] Processing volume...\n",
      "training: [315/527] Processing volume...\n",
      "training: [316/527] Processing volume...\n",
      "training: [317/527] Processing volume...\n",
      "validation step in training epoch 1\n",
      "aorta dissection not manually set, use the value in csv file\n",
      "original image shape: torch.Size([1, 1, 512, 512, 89])\n",
      "inference val set from 10 to 10 batch\n",
      "validation: [1/2] Processing volume...\n",
      "patient ID: 1PC078\n",
      "input volume shape: torch.Size([1, 512, 512, 89])\n",
      "target volume shape: torch.Size([1, 512, 512, 89])\n",
      "ad: tensor(0)\n",
      "modality: tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: [2/2] Processing volume...\n",
      "patient ID: 42025705_4\n",
      "input volume shape: torch.Size([1, 512, 512, 39])\n",
      "target volume shape: torch.Size([1, 512, 512, 39])\n",
      "ad: tensor(0)\n",
      "modality: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: [318/527] Processing volume...\n",
      "training: [319/527] Processing volume...\n",
      "training: [320/527] Processing volume...\n",
      "training: [321/527] Processing volume...\n",
      "training: [322/527] Processing volume...\n",
      "training: [323/527] Processing volume...\n",
      "training: [324/527] Processing volume...\n",
      "training: [325/527] Processing volume...\n",
      "training: [326/527] Processing volume...\n",
      "training: [327/527] Processing volume...\n",
      "training: [328/527] Processing volume...\n",
      "training: [329/527] Processing volume...\n",
      "training: [330/527] Processing volume...\n",
      "training: [331/527] Processing volume...\n",
      "training: [332/527] Processing volume...\n",
      "training: [333/527] Processing volume...\n",
      "training: [334/527] Processing volume...\n",
      "training: [335/527] Processing volume...\n",
      "training: [336/527] Processing volume...\n",
      "training: [337/527] Processing volume...\n",
      "training: [338/527] Processing volume...\n",
      "training: [339/527] Processing volume...\n",
      "training: [340/527] Processing volume...\n",
      "training: [341/527] Processing volume...\n",
      "training: [342/527] Processing volume...\n",
      "training: [343/527] Processing volume...\n",
      "training: [344/527] Processing volume...\n",
      "training: [345/527] Processing volume...\n",
      "training: [346/527] Processing volume...\n",
      "training: [347/527] Processing volume...\n",
      "training: [348/527] Processing volume...\n",
      "training: [349/527] Processing volume...\n",
      "training: [350/527] Processing volume...\n",
      "training: [351/527] Processing volume...\n",
      "training: [352/527] Processing volume...\n",
      "training: [353/527] Processing volume...\n",
      "training: [354/527] Processing volume...\n",
      "training: [355/527] Processing volume...\n",
      "training: [356/527] Processing volume...\n",
      "training: [357/527] Processing volume...\n",
      "training: [358/527] Processing volume...\n",
      "training: [359/527] Processing volume...\n",
      "training: [360/527] Processing volume...\n",
      "training: [361/527] Processing volume...\n",
      "training: [362/527] Processing volume...\n",
      "training: [363/527] Processing volume...\n",
      "training: [364/527] Processing volume...\n",
      "training: [365/527] Processing volume...\n",
      "training: [366/527] Processing volume...\n",
      "training: [367/527] Processing volume...\n",
      "training: [368/527] Processing volume...\n",
      "training: [369/527] Processing volume...\n",
      "training: [370/527] Processing volume...\n",
      "training: [371/527] Processing volume...\n",
      "training: [372/527] Processing volume...\n",
      "training: [373/527] Processing volume...\n",
      "training: [374/527] Processing volume...\n",
      "training: [375/527] Processing volume...\n",
      "validation step in training epoch 1\n",
      "aorta dissection not manually set, use the value in csv file\n",
      "original image shape: torch.Size([1, 1, 512, 512, 89])\n",
      "inference val set from 10 to 10 batch\n",
      "validation: [1/2] Processing volume...\n",
      "patient ID: 1PC078\n",
      "input volume shape: torch.Size([1, 512, 512, 89])\n",
      "target volume shape: torch.Size([1, 512, 512, 89])\n",
      "ad: tensor(0)\n",
      "modality: tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: [2/2] Processing volume...\n",
      "patient ID: 42025705_4\n",
      "input volume shape: torch.Size([1, 512, 512, 39])\n",
      "target volume shape: torch.Size([1, 512, 512, 39])\n",
      "ad: tensor(0)\n",
      "modality: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: [376/527] Processing volume...\n",
      "training: [377/527] Processing volume...\n",
      "training: [378/527] Processing volume...\n",
      "training: [379/527] Processing volume...\n",
      "training: [380/527] Processing volume...\n",
      "training: [381/527] Processing volume...\n",
      "training: [382/527] Processing volume...\n",
      "training: [383/527] Processing volume...\n",
      "training: [384/527] Processing volume...\n",
      "training: [385/527] Processing volume...\n",
      "training: [386/527] Processing volume...\n",
      "training: [387/527] Processing volume...\n",
      "training: [388/527] Processing volume...\n",
      "training: [389/527] Processing volume...\n",
      "training: [390/527] Processing volume...\n",
      "training: [391/527] Processing volume...\n",
      "training: [392/527] Processing volume...\n",
      "training: [393/527] Processing volume...\n",
      "training: [394/527] Processing volume...\n",
      "training: [395/527] Processing volume...\n",
      "training: [396/527] Processing volume...\n",
      "training: [397/527] Processing volume...\n",
      "training: [398/527] Processing volume...\n",
      "training: [399/527] Processing volume...\n",
      "training: [400/527] Processing volume...\n",
      "training: [401/527] Processing volume...\n",
      "training: [402/527] Processing volume...\n",
      "training: [403/527] Processing volume...\n",
      "training: [404/527] Processing volume...\n",
      "training: [405/527] Processing volume...\n",
      "training: [406/527] Processing volume...\n",
      "training: [407/527] Processing volume...\n",
      "training: [408/527] Processing volume...\n",
      "validation step in training epoch 1\n",
      "aorta dissection not manually set, use the value in csv file\n",
      "original image shape: torch.Size([1, 1, 512, 512, 89])\n",
      "inference val set from 10 to 10 batch\n",
      "validation: [1/2] Processing volume...\n",
      "patient ID: 1PC078\n",
      "input volume shape: torch.Size([1, 512, 512, 89])\n",
      "target volume shape: torch.Size([1, 512, 512, 89])\n",
      "ad: tensor(0)\n",
      "modality: tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: [2/2] Processing volume...\n",
      "patient ID: 42025705_4\n",
      "input volume shape: torch.Size([1, 512, 512, 39])\n",
      "target volume shape: torch.Size([1, 512, 512, 39])\n",
      "ad: tensor(0)\n",
      "modality: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: [409/527] Processing volume...\n",
      "training: [410/527] Processing volume...\n",
      "training: [411/527] Processing volume...\n",
      "training: [412/527] Processing volume...\n",
      "training: [413/527] Processing volume...\n",
      "training: [414/527] Processing volume...\n",
      "training: [415/527] Processing volume...\n",
      "training: [416/527] Processing volume...\n",
      "training: [417/527] Processing volume...\n",
      "training: [418/527] Processing volume...\n",
      "training: [419/527] Processing volume...\n",
      "training: [420/527] Processing volume...\n",
      "training: [421/527] Processing volume...\n",
      "training: [422/527] Processing volume...\n",
      "training: [423/527] Processing volume...\n",
      "training: [424/527] Processing volume...\n",
      "training: [425/527] Processing volume...\n",
      "training: [426/527] Processing volume...\n",
      "validation step in training epoch 1\n",
      "aorta dissection not manually set, use the value in csv file\n",
      "original image shape: torch.Size([1, 1, 512, 512, 89])\n",
      "inference val set from 10 to 10 batch\n",
      "validation: [1/2] Processing volume...\n",
      "patient ID: 1PC078\n",
      "input volume shape: torch.Size([1, 512, 512, 89])\n",
      "target volume shape: torch.Size([1, 512, 512, 89])\n",
      "ad: tensor(0)\n",
      "modality: tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: [2/2] Processing volume...\n",
      "patient ID: 42025705_4\n",
      "input volume shape: torch.Size([1, 512, 512, 39])\n",
      "target volume shape: torch.Size([1, 512, 512, 39])\n",
      "ad: tensor(0)\n",
      "modality: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: [427/527] Processing volume...\n",
      "training: [428/527] Processing volume...\n",
      "training: [429/527] Processing volume...\n",
      "training: [430/527] Processing volume...\n",
      "training: [431/527] Processing volume...\n",
      "training: [432/527] Processing volume...\n",
      "training: [433/527] Processing volume...\n",
      "training: [434/527] Processing volume...\n",
      "training: [435/527] Processing volume...\n",
      "training: [436/527] Processing volume...\n",
      "training: [437/527] Processing volume...\n",
      "training: [438/527] Processing volume...\n",
      "training: [439/527] Processing volume...\n",
      "training: [440/527] Processing volume...\n",
      "training: [441/527] Processing volume...\n",
      "training: [442/527] Processing volume...\n",
      "training: [443/527] Processing volume...\n",
      "training: [444/527] Processing volume...\n",
      "validation step in training epoch 1\n",
      "aorta dissection not manually set, use the value in csv file\n",
      "original image shape: torch.Size([1, 1, 512, 512, 89])\n",
      "inference val set from 10 to 10 batch\n",
      "validation: [1/2] Processing volume...\n",
      "patient ID: 1PC078\n",
      "input volume shape: torch.Size([1, 512, 512, 89])\n",
      "target volume shape: torch.Size([1, 512, 512, 89])\n",
      "ad: tensor(0)\n",
      "modality: tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: [2/2] Processing volume...\n",
      "patient ID: 42025705_4\n",
      "input volume shape: torch.Size([1, 512, 512, 39])\n",
      "target volume shape: torch.Size([1, 512, 512, 39])\n",
      "ad: tensor(0)\n",
      "modality: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: [445/527] Processing volume...\n",
      "training: [446/527] Processing volume...\n",
      "training: [447/527] Processing volume...\n",
      "training: [448/527] Processing volume...\n",
      "training: [449/527] Processing volume...\n",
      "training: [450/527] Processing volume...\n",
      "training: [451/527] Processing volume...\n",
      "training: [452/527] Processing volume...\n",
      "training: [453/527] Processing volume...\n",
      "training: [454/527] Processing volume...\n",
      "training: [455/527] Processing volume...\n",
      "training: [456/527] Processing volume...\n",
      "training: [457/527] Processing volume...\n",
      "training: [458/527] Processing volume...\n",
      "training: [459/527] Processing volume...\n",
      "training: [460/527] Processing volume...\n",
      "training: [461/527] Processing volume...\n",
      "training: [462/527] Processing volume...\n",
      "validation step in training epoch 1\n",
      "aorta dissection not manually set, use the value in csv file\n",
      "original image shape: torch.Size([1, 1, 512, 512, 89])\n",
      "inference val set from 10 to 10 batch\n",
      "validation: [1/2] Processing volume...\n",
      "patient ID: 1PC078\n",
      "input volume shape: torch.Size([1, 512, 512, 89])\n",
      "target volume shape: torch.Size([1, 512, 512, 89])\n",
      "ad: tensor(0)\n",
      "modality: tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: [2/2] Processing volume...\n",
      "patient ID: 42025705_4\n",
      "input volume shape: torch.Size([1, 512, 512, 39])\n",
      "target volume shape: torch.Size([1, 512, 512, 39])\n",
      "ad: tensor(0)\n",
      "modality: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: [463/527] Processing volume...\n",
      "training: [464/527] Processing volume...\n",
      "training: [465/527] Processing volume...\n",
      "training: [466/527] Processing volume...\n",
      "training: [467/527] Processing volume...\n",
      "training: [468/527] Processing volume...\n",
      "training: [469/527] Processing volume...\n",
      "training: [470/527] Processing volume...\n",
      "training: [471/527] Processing volume...\n",
      "training: [472/527] Processing volume...\n",
      "training: [473/527] Processing volume...\n",
      "training: [474/527] Processing volume...\n",
      "training: [475/527] Processing volume...\n",
      "training: [476/527] Processing volume...\n",
      "training: [477/527] Processing volume...\n",
      "training: [478/527] Processing volume...\n",
      "training: [479/527] Processing volume...\n",
      "training: [480/527] Processing volume...\n",
      "validation step in training epoch 1\n",
      "aorta dissection not manually set, use the value in csv file\n",
      "original image shape: torch.Size([1, 1, 512, 512, 89])\n",
      "inference val set from 10 to 10 batch\n",
      "validation: [1/2] Processing volume...\n",
      "patient ID: 1PC078\n",
      "input volume shape: torch.Size([1, 512, 512, 89])\n",
      "target volume shape: torch.Size([1, 512, 512, 89])\n",
      "ad: tensor(0)\n",
      "modality: tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: [2/2] Processing volume...\n",
      "patient ID: 42025705_4\n",
      "input volume shape: torch.Size([1, 512, 512, 39])\n",
      "target volume shape: torch.Size([1, 512, 512, 39])\n",
      "ad: tensor(0)\n",
      "modality: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: [481/527] Processing volume...\n",
      "training: [482/527] Processing volume...\n",
      "training: [483/527] Processing volume...\n",
      "training: [484/527] Processing volume...\n",
      "training: [485/527] Processing volume...\n",
      "training: [486/527] Processing volume...\n",
      "training: [487/527] Processing volume...\n",
      "training: [488/527] Processing volume...\n",
      "training: [489/527] Processing volume...\n",
      "training: [490/527] Processing volume...\n",
      "training: [491/527] Processing volume...\n",
      "training: [492/527] Processing volume...\n",
      "training: [493/527] Processing volume...\n",
      "training: [494/527] Processing volume...\n",
      "training: [495/527] Processing volume...\n",
      "training: [496/527] Processing volume...\n",
      "training: [497/527] Processing volume...\n",
      "validation step in training epoch 1\n",
      "aorta dissection not manually set, use the value in csv file\n",
      "original image shape: torch.Size([1, 1, 512, 512, 89])\n",
      "inference val set from 10 to 10 batch\n",
      "validation: [1/2] Processing volume...\n",
      "patient ID: 1PC078\n",
      "input volume shape: torch.Size([1, 512, 512, 89])\n",
      "target volume shape: torch.Size([1, 512, 512, 89])\n",
      "ad: tensor(0)\n",
      "modality: tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: [2/2] Processing volume...\n",
      "patient ID: 42025705_4\n",
      "input volume shape: torch.Size([1, 512, 512, 39])\n",
      "target volume shape: torch.Size([1, 512, 512, 39])\n",
      "ad: tensor(0)\n",
      "modality: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: [498/527] Processing volume...\n",
      "training: [499/527] Processing volume...\n",
      "training: [500/527] Processing volume...\n",
      "training: [501/527] Processing volume...\n",
      "training: [502/527] Processing volume...\n",
      "training: [503/527] Processing volume...\n",
      "training: [504/527] Processing volume...\n",
      "training: [505/527] Processing volume...\n",
      "training: [506/527] Processing volume...\n",
      "training: [507/527] Processing volume...\n",
      "training: [508/527] Processing volume...\n",
      "training: [509/527] Processing volume...\n",
      "training: [510/527] Processing volume...\n",
      "training: [511/527] Processing volume...\n",
      "training: [512/527] Processing volume...\n",
      "training: [513/527] Processing volume...\n",
      "training: [514/527] Processing volume...\n",
      "training: [515/527] Processing volume...\n",
      "validation step in training epoch 1\n",
      "aorta dissection not manually set, use the value in csv file\n",
      "original image shape: torch.Size([1, 1, 512, 512, 89])\n",
      "inference val set from 10 to 10 batch\n",
      "validation: [1/2] Processing volume...\n",
      "patient ID: 1PC078\n",
      "input volume shape: torch.Size([1, 512, 512, 89])\n",
      "target volume shape: torch.Size([1, 512, 512, 89])\n",
      "ad: tensor(0)\n",
      "modality: tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: [2/2] Processing volume...\n",
      "patient ID: 42025705_4\n",
      "input volume shape: torch.Size([1, 512, 512, 39])\n",
      "target volume shape: torch.Size([1, 512, 512, 39])\n",
      "ad: tensor(0)\n",
      "modality: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: [516/527] Processing volume...\n",
      "training: [517/527] Processing volume...\n",
      "training: [518/527] Processing volume...\n",
      "training: [519/527] Processing volume...\n",
      "training: [520/527] Processing volume...\n",
      "training: [521/527] Processing volume...\n",
      "training: [522/527] Processing volume...\n",
      "training: [523/527] Processing volume...\n",
      "training: [524/527] Processing volume...\n",
      "training: [525/527] Processing volume...\n",
      "training: [526/527] Processing volume...\n",
      "training: [527/527] Processing volume...\n",
      "validation step in training epoch 1\n",
      "aorta dissection not manually set, use the value in csv file\n",
      "original image shape: torch.Size([1, 1, 512, 512, 89])\n",
      "inference val set from 10 to 10 batch\n",
      "validation: [1/2] Processing volume...\n",
      "patient ID: 1PC078\n",
      "input volume shape: torch.Size([1, 512, 512, 89])\n",
      "target volume shape: torch.Size([1, 512, 512, 89])\n",
      "ad: tensor(0)\n",
      "modality: tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 12.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: [2/2] Processing volume...\n",
      "patient ID: 42025705_4\n",
      "input volume shape: torch.Size([1, 512, 512, 39])\n",
      "target volume shape: torch.Size([1, 512, 512, 39])\n",
      "ad: tensor(0)\n",
      "modality: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original image shape: torch.Size([1, 1, 512, 512, 149])\n",
      "training: [1/527] Processing volume...\n",
      "training: [2/527] Processing volume...\n",
      "training: [3/527] Processing volume...\n",
      "training: [4/527] Processing volume...\n",
      "training: [5/527] Processing volume...\n",
      "training: [6/527] Processing volume...\n",
      "training: [7/527] Processing volume...\n",
      "training: [8/527] Processing volume...\n",
      "training: [9/527] Processing volume...\n",
      "training: [10/527] Processing volume...\n",
      "training: [11/527] Processing volume...\n",
      "validation step in training epoch 2\n",
      "aorta dissection not manually set, use the value in csv file\n",
      "original image shape: torch.Size([1, 1, 512, 512, 89])\n",
      "inference val set from 10 to 10 batch\n",
      "validation: [1/2] Processing volume...\n",
      "patient ID: 1PC078\n",
      "input volume shape: torch.Size([1, 512, 512, 89])\n",
      "target volume shape: torch.Size([1, 512, 512, 89])\n",
      "ad: tensor(0)\n",
      "modality: tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 12.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: [2/2] Processing volume...\n",
      "patient ID: 42025705_4\n",
      "input volume shape: torch.Size([1, 512, 512, 39])\n",
      "target volume shape: torch.Size([1, 512, 512, 39])\n",
      "ad: tensor(0)\n",
      "modality: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: [12/527] Processing volume...\n",
      "training: [13/527] Processing volume...\n",
      "training: [14/527] Processing volume...\n",
      "training: [15/527] Processing volume...\n",
      "training: [16/527] Processing volume...\n",
      "training: [17/527] Processing volume...\n",
      "training: [18/527] Processing volume...\n",
      "training: [19/527] Processing volume...\n",
      "training: [20/527] Processing volume...\n",
      "training: [21/527] Processing volume...\n",
      "training: [22/527] Processing volume...\n",
      "training: [23/527] Processing volume...\n",
      "training: [24/527] Processing volume...\n",
      "training: [25/527] Processing volume...\n",
      "training: [26/527] Processing volume...\n",
      "training: [27/527] Processing volume...\n",
      "training: [28/527] Processing volume...\n",
      "training: [29/527] Processing volume...\n",
      "training: [30/527] Processing volume...\n",
      "training: [31/527] Processing volume...\n",
      "training: [32/527] Processing volume...\n",
      "training: [33/527] Processing volume...\n",
      "training: [34/527] Processing volume...\n",
      "training: [35/527] Processing volume...\n",
      "training: [36/527] Processing volume...\n",
      "training: [37/527] Processing volume...\n",
      "training: [38/527] Processing volume...\n",
      "training: [39/527] Processing volume...\n",
      "training: [40/527] Processing volume...\n",
      "training: [41/527] Processing volume...\n",
      "training: [42/527] Processing volume...\n",
      "training: [43/527] Processing volume...\n",
      "training: [44/527] Processing volume...\n",
      "training: [45/527] Processing volume...\n",
      "validation step in training epoch 2\n",
      "aorta dissection not manually set, use the value in csv file\n",
      "original image shape: torch.Size([1, 1, 512, 512, 89])\n",
      "inference val set from 10 to 10 batch\n",
      "validation: [1/2] Processing volume...\n",
      "patient ID: 1PC078\n",
      "input volume shape: torch.Size([1, 512, 512, 89])\n",
      "target volume shape: torch.Size([1, 512, 512, 89])\n",
      "ad: tensor(0)\n",
      "modality: tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: [2/2] Processing volume...\n",
      "patient ID: 42025705_4\n",
      "input volume shape: torch.Size([1, 512, 512, 39])\n",
      "target volume shape: torch.Size([1, 512, 512, 39])\n",
      "ad: tensor(0)\n",
      "modality: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: [46/527] Processing volume...\n",
      "training: [47/527] Processing volume...\n",
      "training: [48/527] Processing volume...\n",
      "training: [49/527] Processing volume...\n",
      "training: [50/527] Processing volume...\n",
      "training: [51/527] Processing volume...\n",
      "training: [52/527] Processing volume...\n",
      "training: [53/527] Processing volume...\n",
      "training: [54/527] Processing volume...\n",
      "training: [55/527] Processing volume...\n",
      "training: [56/527] Processing volume...\n",
      "training: [57/527] Processing volume...\n",
      "training: [58/527] Processing volume...\n",
      "training: [59/527] Processing volume...\n",
      "training: [60/527] Processing volume...\n",
      "training: [61/527] Processing volume...\n",
      "training: [62/527] Processing volume...\n",
      "training: [63/527] Processing volume...\n",
      "training: [64/527] Processing volume...\n",
      "training: [65/527] Processing volume...\n",
      "training: [66/527] Processing volume...\n",
      "training: [67/527] Processing volume...\n",
      "training: [68/527] Processing volume...\n",
      "training: [69/527] Processing volume...\n",
      "training: [70/527] Processing volume...\n",
      "training: [71/527] Processing volume...\n",
      "training: [72/527] Processing volume...\n",
      "training: [73/527] Processing volume...\n",
      "training: [74/527] Processing volume...\n",
      "training: [75/527] Processing volume...\n",
      "training: [76/527] Processing volume...\n",
      "training: [77/527] Processing volume...\n",
      "training: [78/527] Processing volume...\n",
      "validation step in training epoch 2\n",
      "aorta dissection not manually set, use the value in csv file\n",
      "original image shape: torch.Size([1, 1, 512, 512, 89])\n",
      "inference val set from 10 to 10 batch\n",
      "validation: [1/2] Processing volume...\n",
      "patient ID: 1PC078\n",
      "input volume shape: torch.Size([1, 512, 512, 89])\n",
      "target volume shape: torch.Size([1, 512, 512, 89])\n",
      "ad: tensor(0)\n",
      "modality: tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: [2/2] Processing volume...\n",
      "patient ID: 42025705_4\n",
      "input volume shape: torch.Size([1, 512, 512, 39])\n",
      "target volume shape: torch.Size([1, 512, 512, 39])\n",
      "ad: tensor(0)\n",
      "modality: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: [79/527] Processing volume...\n",
      "training: [80/527] Processing volume...\n",
      "training: [81/527] Processing volume...\n",
      "training: [82/527] Processing volume...\n",
      "training: [83/527] Processing volume...\n",
      "training: [84/527] Processing volume...\n",
      "training: [85/527] Processing volume...\n",
      "training: [86/527] Processing volume...\n",
      "training: [87/527] Processing volume...\n",
      "training: [88/527] Processing volume...\n",
      "training: [89/527] Processing volume...\n",
      "training: [90/527] Processing volume...\n",
      "training: [91/527] Processing volume...\n",
      "training: [92/527] Processing volume...\n",
      "training: [93/527] Processing volume...\n",
      "training: [94/527] Processing volume...\n",
      "training: [95/527] Processing volume...\n",
      "training: [96/527] Processing volume...\n",
      "training: [97/527] Processing volume...\n",
      "training: [98/527] Processing volume...\n",
      "training: [99/527] Processing volume...\n",
      "training: [100/527] Processing volume...\n",
      "training: [101/527] Processing volume...\n",
      "training: [102/527] Processing volume...\n",
      "training: [103/527] Processing volume...\n",
      "training: [104/527] Processing volume...\n",
      "training: [105/527] Processing volume...\n",
      "training: [106/527] Processing volume...\n",
      "training: [107/527] Processing volume...\n",
      "training: [108/527] Processing volume...\n",
      "training: [109/527] Processing volume...\n",
      "training: [110/527] Processing volume...\n",
      "training: [111/527] Processing volume...\n",
      "training: [112/527] Processing volume...\n",
      "validation step in training epoch 2\n",
      "aorta dissection not manually set, use the value in csv file\n",
      "original image shape: torch.Size([1, 1, 512, 512, 89])\n",
      "inference val set from 10 to 10 batch\n",
      "validation: [1/2] Processing volume...\n",
      "patient ID: 1PC078\n",
      "input volume shape: torch.Size([1, 512, 512, 89])\n",
      "target volume shape: torch.Size([1, 512, 512, 89])\n",
      "ad: tensor(0)\n",
      "modality: tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: [2/2] Processing volume...\n",
      "patient ID: 42025705_4\n",
      "input volume shape: torch.Size([1, 512, 512, 39])\n",
      "target volume shape: torch.Size([1, 512, 512, 39])\n",
      "ad: tensor(0)\n",
      "modality: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: [113/527] Processing volume...\n",
      "training: [114/527] Processing volume...\n",
      "training: [115/527] Processing volume...\n",
      "training: [116/527] Processing volume...\n",
      "training: [117/527] Processing volume...\n",
      "training: [118/527] Processing volume...\n",
      "training: [119/527] Processing volume...\n",
      "training: [120/527] Processing volume...\n",
      "training: [121/527] Processing volume...\n",
      "training: [122/527] Processing volume...\n",
      "training: [123/527] Processing volume...\n",
      "training: [124/527] Processing volume...\n",
      "training: [125/527] Processing volume...\n",
      "training: [126/527] Processing volume...\n",
      "training: [127/527] Processing volume...\n",
      "training: [128/527] Processing volume...\n",
      "training: [129/527] Processing volume...\n",
      "training: [130/527] Processing volume...\n",
      "training: [131/527] Processing volume...\n",
      "training: [132/527] Processing volume...\n",
      "training: [133/527] Processing volume...\n",
      "training: [134/527] Processing volume...\n",
      "training: [135/527] Processing volume...\n",
      "training: [136/527] Processing volume...\n",
      "training: [137/527] Processing volume...\n",
      "training: [138/527] Processing volume...\n",
      "training: [139/527] Processing volume...\n",
      "training: [140/527] Processing volume...\n",
      "training: [141/527] Processing volume...\n",
      "training: [142/527] Processing volume...\n",
      "training: [143/527] Processing volume...\n",
      "training: [144/527] Processing volume...\n",
      "training: [145/527] Processing volume...\n",
      "training: [146/527] Processing volume...\n",
      "validation step in training epoch 2\n",
      "aorta dissection not manually set, use the value in csv file\n",
      "original image shape: torch.Size([1, 1, 512, 512, 89])\n",
      "inference val set from 10 to 10 batch\n",
      "validation: [1/2] Processing volume...\n",
      "patient ID: 1PC078\n",
      "input volume shape: torch.Size([1, 512, 512, 89])\n",
      "target volume shape: torch.Size([1, 512, 512, 89])\n",
      "ad: tensor(0)\n",
      "modality: tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 12.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: [2/2] Processing volume...\n",
      "patient ID: 42025705_4\n",
      "input volume shape: torch.Size([1, 512, 512, 39])\n",
      "target volume shape: torch.Size([1, 512, 512, 39])\n",
      "ad: tensor(0)\n",
      "modality: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: [147/527] Processing volume...\n",
      "training: [148/527] Processing volume...\n",
      "training: [149/527] Processing volume...\n",
      "training: [150/527] Processing volume...\n",
      "training: [151/527] Processing volume...\n",
      "training: [152/527] Processing volume...\n",
      "training: [153/527] Processing volume...\n",
      "training: [154/527] Processing volume...\n",
      "training: [155/527] Processing volume...\n",
      "training: [156/527] Processing volume...\n",
      "training: [157/527] Processing volume...\n",
      "training: [158/527] Processing volume...\n",
      "training: [159/527] Processing volume...\n",
      "training: [160/527] Processing volume...\n",
      "training: [161/527] Processing volume...\n",
      "training: [162/527] Processing volume...\n",
      "training: [163/527] Processing volume...\n",
      "training: [164/527] Processing volume...\n",
      "training: [165/527] Processing volume...\n",
      "training: [166/527] Processing volume...\n",
      "training: [167/527] Processing volume...\n",
      "training: [168/527] Processing volume...\n",
      "training: [169/527] Processing volume...\n",
      "training: [170/527] Processing volume...\n",
      "training: [171/527] Processing volume...\n",
      "training: [172/527] Processing volume...\n",
      "training: [173/527] Processing volume...\n",
      "training: [174/527] Processing volume...\n",
      "training: [175/527] Processing volume...\n",
      "training: [176/527] Processing volume...\n",
      "training: [177/527] Processing volume...\n",
      "training: [178/527] Processing volume...\n",
      "validation step in training epoch 2\n",
      "aorta dissection not manually set, use the value in csv file\n",
      "original image shape: torch.Size([1, 1, 512, 512, 89])\n",
      "inference val set from 10 to 10 batch\n",
      "validation: [1/2] Processing volume...\n",
      "patient ID: 1PC078\n",
      "input volume shape: torch.Size([1, 512, 512, 89])\n",
      "target volume shape: torch.Size([1, 512, 512, 89])\n",
      "ad: tensor(0)\n",
      "modality: tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 12.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: [2/2] Processing volume...\n",
      "patient ID: 42025705_4\n",
      "input volume shape: torch.Size([1, 512, 512, 39])\n",
      "target volume shape: torch.Size([1, 512, 512, 39])\n",
      "ad: tensor(0)\n",
      "modality: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: [179/527] Processing volume...\n",
      "training: [180/527] Processing volume...\n",
      "training: [181/527] Processing volume...\n",
      "training: [182/527] Processing volume...\n",
      "training: [183/527] Processing volume...\n",
      "training: [184/527] Processing volume...\n",
      "training: [185/527] Processing volume...\n",
      "training: [186/527] Processing volume...\n",
      "training: [187/527] Processing volume...\n",
      "training: [188/527] Processing volume...\n",
      "training: [189/527] Processing volume...\n",
      "training: [190/527] Processing volume...\n",
      "training: [191/527] Processing volume...\n",
      "training: [192/527] Processing volume...\n",
      "training: [193/527] Processing volume...\n",
      "training: [194/527] Processing volume...\n",
      "training: [195/527] Processing volume...\n",
      "training: [196/527] Processing volume...\n",
      "training: [197/527] Processing volume...\n",
      "training: [198/527] Processing volume...\n",
      "training: [199/527] Processing volume...\n",
      "training: [200/527] Processing volume...\n",
      "training: [201/527] Processing volume...\n",
      "training: [202/527] Processing volume...\n",
      "training: [203/527] Processing volume...\n",
      "training: [204/527] Processing volume...\n",
      "training: [205/527] Processing volume...\n",
      "training: [206/527] Processing volume...\n",
      "training: [207/527] Processing volume...\n",
      "validation step in training epoch 2\n",
      "aorta dissection not manually set, use the value in csv file\n",
      "original image shape: torch.Size([1, 1, 512, 512, 89])\n",
      "inference val set from 10 to 10 batch\n",
      "validation: [1/2] Processing volume...\n",
      "patient ID: 1PC078\n",
      "input volume shape: torch.Size([1, 512, 512, 89])\n",
      "target volume shape: torch.Size([1, 512, 512, 89])\n",
      "ad: tensor(0)\n",
      "modality: tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 12.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: [2/2] Processing volume...\n",
      "patient ID: 42025705_4\n",
      "input volume shape: torch.Size([1, 512, 512, 39])\n",
      "target volume shape: torch.Size([1, 512, 512, 39])\n",
      "ad: tensor(0)\n",
      "modality: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: [208/527] Processing volume...\n",
      "training: [209/527] Processing volume...\n",
      "training: [210/527] Processing volume...\n",
      "training: [211/527] Processing volume...\n",
      "training: [212/527] Processing volume...\n",
      "training: [213/527] Processing volume...\n",
      "training: [214/527] Processing volume...\n",
      "training: [215/527] Processing volume...\n",
      "training: [216/527] Processing volume...\n",
      "training: [217/527] Processing volume...\n",
      "training: [218/527] Processing volume...\n",
      "training: [219/527] Processing volume...\n",
      "training: [220/527] Processing volume...\n",
      "training: [221/527] Processing volume...\n",
      "training: [222/527] Processing volume...\n",
      "training: [223/527] Processing volume...\n",
      "training: [224/527] Processing volume...\n",
      "training: [225/527] Processing volume...\n",
      "training: [226/527] Processing volume...\n",
      "training: [227/527] Processing volume...\n",
      "training: [228/527] Processing volume...\n",
      "training: [229/527] Processing volume...\n",
      "training: [230/527] Processing volume...\n",
      "training: [231/527] Processing volume...\n",
      "training: [232/527] Processing volume...\n",
      "training: [233/527] Processing volume...\n",
      "training: [234/527] Processing volume...\n",
      "training: [235/527] Processing volume...\n",
      "training: [236/527] Processing volume...\n",
      "training: [237/527] Processing volume...\n",
      "training: [238/527] Processing volume...\n",
      "validation step in training epoch 2\n",
      "aorta dissection not manually set, use the value in csv file\n",
      "original image shape: torch.Size([1, 1, 512, 512, 89])\n",
      "inference val set from 10 to 10 batch\n",
      "validation: [1/2] Processing volume...\n",
      "patient ID: 1PC078\n",
      "input volume shape: torch.Size([1, 512, 512, 89])\n",
      "target volume shape: torch.Size([1, 512, 512, 89])\n",
      "ad: tensor(0)\n",
      "modality: tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: [2/2] Processing volume...\n",
      "patient ID: 42025705_4\n",
      "input volume shape: torch.Size([1, 512, 512, 39])\n",
      "target volume shape: torch.Size([1, 512, 512, 39])\n",
      "ad: tensor(0)\n",
      "modality: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: [239/527] Processing volume...\n",
      "training: [240/527] Processing volume...\n",
      "training: [241/527] Processing volume...\n",
      "training: [242/527] Processing volume...\n",
      "training: [243/527] Processing volume...\n",
      "training: [244/527] Processing volume...\n",
      "training: [245/527] Processing volume...\n",
      "training: [246/527] Processing volume...\n",
      "training: [247/527] Processing volume...\n",
      "training: [248/527] Processing volume...\n",
      "training: [249/527] Processing volume...\n",
      "training: [250/527] Processing volume...\n",
      "training: [251/527] Processing volume...\n",
      "training: [252/527] Processing volume...\n",
      "training: [253/527] Processing volume...\n",
      "training: [254/527] Processing volume...\n",
      "training: [255/527] Processing volume...\n",
      "training: [256/527] Processing volume...\n",
      "training: [257/527] Processing volume...\n",
      "training: [258/527] Processing volume...\n",
      "training: [259/527] Processing volume...\n",
      "training: [260/527] Processing volume...\n",
      "training: [261/527] Processing volume...\n",
      "training: [262/527] Processing volume...\n",
      "training: [263/527] Processing volume...\n",
      "training: [264/527] Processing volume...\n",
      "training: [265/527] Processing volume...\n",
      "training: [266/527] Processing volume...\n",
      "training: [267/527] Processing volume...\n",
      "training: [268/527] Processing volume...\n",
      "training: [269/527] Processing volume...\n",
      "training: [270/527] Processing volume...\n",
      "training: [271/527] Processing volume...\n",
      "training: [272/527] Processing volume...\n",
      "training: [273/527] Processing volume...\n",
      "training: [274/527] Processing volume...\n",
      "training: [275/527] Processing volume...\n",
      "training: [276/527] Processing volume...\n",
      "training: [277/527] Processing volume...\n",
      "training: [278/527] Processing volume...\n",
      "training: [279/527] Processing volume...\n",
      "training: [280/527] Processing volume...\n",
      "training: [281/527] Processing volume...\n",
      "validation step in training epoch 2\n",
      "aorta dissection not manually set, use the value in csv file\n",
      "original image shape: torch.Size([1, 1, 512, 512, 89])\n",
      "inference val set from 10 to 10 batch\n",
      "validation: [1/2] Processing volume...\n",
      "patient ID: 1PC078\n",
      "input volume shape: torch.Size([1, 512, 512, 89])\n",
      "target volume shape: torch.Size([1, 512, 512, 89])\n",
      "ad: tensor(0)\n",
      "modality: tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 12.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: [2/2] Processing volume...\n",
      "patient ID: 42025705_4\n",
      "input volume shape: torch.Size([1, 512, 512, 39])\n",
      "target volume shape: torch.Size([1, 512, 512, 39])\n",
      "ad: tensor(0)\n",
      "modality: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: [282/527] Processing volume...\n",
      "training: [283/527] Processing volume...\n",
      "training: [284/527] Processing volume...\n",
      "training: [285/527] Processing volume...\n",
      "training: [286/527] Processing volume...\n",
      "training: [287/527] Processing volume...\n",
      "training: [288/527] Processing volume...\n",
      "training: [289/527] Processing volume...\n",
      "training: [290/527] Processing volume...\n",
      "training: [291/527] Processing volume...\n",
      "training: [292/527] Processing volume...\n",
      "training: [293/527] Processing volume...\n",
      "training: [294/527] Processing volume...\n",
      "training: [295/527] Processing volume...\n",
      "training: [296/527] Processing volume...\n",
      "training: [297/527] Processing volume...\n",
      "training: [298/527] Processing volume...\n",
      "training: [299/527] Processing volume...\n",
      "training: [300/527] Processing volume...\n",
      "training: [301/527] Processing volume...\n",
      "training: [302/527] Processing volume...\n",
      "training: [303/527] Processing volume...\n",
      "training: [304/527] Processing volume...\n",
      "training: [305/527] Processing volume...\n",
      "training: [306/527] Processing volume...\n",
      "training: [307/527] Processing volume...\n",
      "training: [308/527] Processing volume...\n",
      "training: [309/527] Processing volume...\n",
      "training: [310/527] Processing volume...\n",
      "training: [311/527] Processing volume...\n",
      "training: [312/527] Processing volume...\n",
      "training: [313/527] Processing volume...\n",
      "training: [314/527] Processing volume...\n",
      "training: [315/527] Processing volume...\n",
      "training: [316/527] Processing volume...\n",
      "training: [317/527] Processing volume...\n",
      "training: [318/527] Processing volume...\n",
      "training: [319/527] Processing volume...\n",
      "training: [320/527] Processing volume...\n",
      "training: [321/527] Processing volume...\n",
      "training: [322/527] Processing volume...\n",
      "training: [323/527] Processing volume...\n",
      "training: [324/527] Processing volume...\n",
      "training: [325/527] Processing volume...\n",
      "training: [326/527] Processing volume...\n",
      "training: [327/527] Processing volume...\n",
      "training: [328/527] Processing volume...\n",
      "training: [329/527] Processing volume...\n",
      "training: [330/527] Processing volume...\n",
      "training: [331/527] Processing volume...\n",
      "training: [332/527] Processing volume...\n",
      "training: [333/527] Processing volume...\n",
      "training: [334/527] Processing volume...\n",
      "training: [335/527] Processing volume...\n",
      "validation step in training epoch 2\n",
      "aorta dissection not manually set, use the value in csv file\n",
      "original image shape: torch.Size([1, 1, 512, 512, 89])\n",
      "inference val set from 10 to 10 batch\n",
      "validation: [1/2] Processing volume...\n",
      "patient ID: 1PC078\n",
      "input volume shape: torch.Size([1, 512, 512, 89])\n",
      "target volume shape: torch.Size([1, 512, 512, 89])\n",
      "ad: tensor(0)\n",
      "modality: tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: [2/2] Processing volume...\n",
      "patient ID: 42025705_4\n",
      "input volume shape: torch.Size([1, 512, 512, 39])\n",
      "target volume shape: torch.Size([1, 512, 512, 39])\n",
      "ad: tensor(0)\n",
      "modality: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: [336/527] Processing volume...\n",
      "training: [337/527] Processing volume...\n",
      "training: [338/527] Processing volume...\n",
      "training: [339/527] Processing volume...\n",
      "training: [340/527] Processing volume...\n",
      "training: [341/527] Processing volume...\n",
      "training: [342/527] Processing volume...\n",
      "training: [343/527] Processing volume...\n",
      "training: [344/527] Processing volume...\n",
      "training: [345/527] Processing volume...\n",
      "training: [346/527] Processing volume...\n",
      "training: [347/527] Processing volume...\n",
      "training: [348/527] Processing volume...\n",
      "training: [349/527] Processing volume...\n",
      "training: [350/527] Processing volume...\n",
      "training: [351/527] Processing volume...\n",
      "training: [352/527] Processing volume...\n",
      "training: [353/527] Processing volume...\n",
      "training: [354/527] Processing volume...\n",
      "training: [355/527] Processing volume...\n",
      "training: [356/527] Processing volume...\n",
      "training: [357/527] Processing volume...\n",
      "training: [358/527] Processing volume...\n",
      "training: [359/527] Processing volume...\n",
      "training: [360/527] Processing volume...\n",
      "training: [361/527] Processing volume...\n",
      "training: [362/527] Processing volume...\n",
      "training: [363/527] Processing volume...\n",
      "training: [364/527] Processing volume...\n",
      "training: [365/527] Processing volume...\n",
      "training: [366/527] Processing volume...\n",
      "training: [367/527] Processing volume...\n",
      "training: [368/527] Processing volume...\n",
      "training: [369/527] Processing volume...\n",
      "training: [370/527] Processing volume...\n",
      "training: [371/527] Processing volume...\n",
      "training: [372/527] Processing volume...\n",
      "training: [373/527] Processing volume...\n",
      "training: [374/527] Processing volume...\n",
      "training: [375/527] Processing volume...\n",
      "training: [376/527] Processing volume...\n",
      "training: [377/527] Processing volume...\n",
      "training: [378/527] Processing volume...\n",
      "training: [379/527] Processing volume...\n",
      "training: [380/527] Processing volume...\n",
      "training: [381/527] Processing volume...\n",
      "training: [382/527] Processing volume...\n",
      "training: [383/527] Processing volume...\n",
      "training: [384/527] Processing volume...\n",
      "training: [385/527] Processing volume...\n",
      "training: [386/527] Processing volume...\n",
      "training: [387/527] Processing volume...\n",
      "training: [388/527] Processing volume...\n",
      "training: [389/527] Processing volume...\n",
      "training: [390/527] Processing volume...\n",
      "training: [391/527] Processing volume...\n",
      "training: [392/527] Processing volume...\n",
      "training: [393/527] Processing volume...\n",
      "validation step in training epoch 2\n",
      "aorta dissection not manually set, use the value in csv file\n",
      "original image shape: torch.Size([1, 1, 512, 512, 89])\n",
      "inference val set from 10 to 10 batch\n",
      "validation: [1/2] Processing volume...\n",
      "patient ID: 1PC078\n",
      "input volume shape: torch.Size([1, 512, 512, 89])\n",
      "target volume shape: torch.Size([1, 512, 512, 89])\n",
      "ad: tensor(0)\n",
      "modality: tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: [2/2] Processing volume...\n",
      "patient ID: 42025705_4\n",
      "input volume shape: torch.Size([1, 512, 512, 39])\n",
      "target volume shape: torch.Size([1, 512, 512, 39])\n",
      "ad: tensor(0)\n",
      "modality: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: [394/527] Processing volume...\n",
      "training: [395/527] Processing volume...\n",
      "training: [396/527] Processing volume...\n",
      "training: [397/527] Processing volume...\n",
      "training: [398/527] Processing volume...\n",
      "training: [399/527] Processing volume...\n",
      "training: [400/527] Processing volume...\n",
      "training: [401/527] Processing volume...\n",
      "training: [402/527] Processing volume...\n",
      "training: [403/527] Processing volume...\n",
      "training: [404/527] Processing volume...\n",
      "training: [405/527] Processing volume...\n",
      "training: [406/527] Processing volume...\n",
      "training: [407/527] Processing volume...\n",
      "training: [408/527] Processing volume...\n",
      "training: [409/527] Processing volume...\n",
      "training: [410/527] Processing volume...\n",
      "training: [411/527] Processing volume...\n",
      "training: [412/527] Processing volume...\n",
      "training: [413/527] Processing volume...\n",
      "training: [414/527] Processing volume...\n",
      "validation step in training epoch 2\n",
      "aorta dissection not manually set, use the value in csv file\n",
      "original image shape: torch.Size([1, 1, 512, 512, 89])\n",
      "inference val set from 10 to 10 batch\n",
      "validation: [1/2] Processing volume...\n",
      "patient ID: 1PC078\n",
      "input volume shape: torch.Size([1, 512, 512, 89])\n",
      "target volume shape: torch.Size([1, 512, 512, 89])\n",
      "ad: tensor(0)\n",
      "modality: tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: [2/2] Processing volume...\n",
      "patient ID: 42025705_4\n",
      "input volume shape: torch.Size([1, 512, 512, 39])\n",
      "target volume shape: torch.Size([1, 512, 512, 39])\n",
      "ad: tensor(0)\n",
      "modality: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: [415/527] Processing volume...\n",
      "training: [416/527] Processing volume...\n",
      "training: [417/527] Processing volume...\n",
      "training: [418/527] Processing volume...\n",
      "training: [419/527] Processing volume...\n",
      "training: [420/527] Processing volume...\n",
      "training: [421/527] Processing volume...\n",
      "training: [422/527] Processing volume...\n",
      "training: [423/527] Processing volume...\n",
      "training: [424/527] Processing volume...\n",
      "training: [425/527] Processing volume...\n",
      "training: [426/527] Processing volume...\n",
      "training: [427/527] Processing volume...\n",
      "training: [428/527] Processing volume...\n",
      "training: [429/527] Processing volume...\n",
      "training: [430/527] Processing volume...\n",
      "training: [431/527] Processing volume...\n",
      "training: [432/527] Processing volume...\n",
      "validation step in training epoch 2\n",
      "aorta dissection not manually set, use the value in csv file\n",
      "original image shape: torch.Size([1, 1, 512, 512, 89])\n",
      "inference val set from 10 to 10 batch\n",
      "validation: [1/2] Processing volume...\n",
      "patient ID: 1PC078\n",
      "input volume shape: torch.Size([1, 512, 512, 89])\n",
      "target volume shape: torch.Size([1, 512, 512, 89])\n",
      "ad: tensor(0)\n",
      "modality: tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: [2/2] Processing volume...\n",
      "patient ID: 42025705_4\n",
      "input volume shape: torch.Size([1, 512, 512, 39])\n",
      "target volume shape: torch.Size([1, 512, 512, 39])\n",
      "ad: tensor(0)\n",
      "modality: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: [433/527] Processing volume...\n",
      "training: [434/527] Processing volume...\n",
      "training: [435/527] Processing volume...\n",
      "training: [436/527] Processing volume...\n",
      "training: [437/527] Processing volume...\n",
      "training: [438/527] Processing volume...\n",
      "training: [439/527] Processing volume...\n",
      "training: [440/527] Processing volume...\n",
      "training: [441/527] Processing volume...\n",
      "training: [442/527] Processing volume...\n",
      "training: [443/527] Processing volume...\n",
      "training: [444/527] Processing volume...\n",
      "training: [445/527] Processing volume...\n",
      "training: [446/527] Processing volume...\n",
      "training: [447/527] Processing volume...\n",
      "training: [448/527] Processing volume...\n",
      "training: [449/527] Processing volume...\n",
      "training: [450/527] Processing volume...\n",
      "validation step in training epoch 2\n",
      "aorta dissection not manually set, use the value in csv file\n",
      "original image shape: torch.Size([1, 1, 512, 512, 89])\n",
      "inference val set from 10 to 10 batch\n",
      "validation: [1/2] Processing volume...\n",
      "patient ID: 1PC078\n",
      "input volume shape: torch.Size([1, 512, 512, 89])\n",
      "target volume shape: torch.Size([1, 512, 512, 89])\n",
      "ad: tensor(0)\n",
      "modality: tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: [2/2] Processing volume...\n",
      "patient ID: 42025705_4\n",
      "input volume shape: torch.Size([1, 512, 512, 39])\n",
      "target volume shape: torch.Size([1, 512, 512, 39])\n",
      "ad: tensor(0)\n",
      "modality: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: [451/527] Processing volume...\n",
      "training: [452/527] Processing volume...\n",
      "training: [453/527] Processing volume...\n",
      "training: [454/527] Processing volume...\n",
      "training: [455/527] Processing volume...\n",
      "training: [456/527] Processing volume...\n",
      "training: [457/527] Processing volume...\n",
      "training: [458/527] Processing volume...\n",
      "training: [459/527] Processing volume...\n",
      "training: [460/527] Processing volume...\n",
      "training: [461/527] Processing volume...\n",
      "training: [462/527] Processing volume...\n",
      "training: [463/527] Processing volume...\n",
      "training: [464/527] Processing volume...\n",
      "training: [465/527] Processing volume...\n",
      "training: [466/527] Processing volume...\n",
      "training: [467/527] Processing volume...\n",
      "validation step in training epoch 2\n",
      "aorta dissection not manually set, use the value in csv file\n",
      "original image shape: torch.Size([1, 1, 512, 512, 89])\n",
      "inference val set from 10 to 10 batch\n",
      "validation: [1/2] Processing volume...\n",
      "patient ID: 1PC078\n",
      "input volume shape: torch.Size([1, 512, 512, 89])\n",
      "target volume shape: torch.Size([1, 512, 512, 89])\n",
      "ad: tensor(0)\n",
      "modality: tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 12.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: [2/2] Processing volume...\n",
      "patient ID: 42025705_4\n",
      "input volume shape: torch.Size([1, 512, 512, 39])\n",
      "target volume shape: torch.Size([1, 512, 512, 39])\n",
      "ad: tensor(0)\n",
      "modality: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: [468/527] Processing volume...\n",
      "training: [469/527] Processing volume...\n",
      "training: [470/527] Processing volume...\n",
      "training: [471/527] Processing volume...\n",
      "training: [472/527] Processing volume...\n",
      "training: [473/527] Processing volume...\n",
      "training: [474/527] Processing volume...\n",
      "training: [475/527] Processing volume...\n",
      "training: [476/527] Processing volume...\n",
      "training: [477/527] Processing volume...\n",
      "training: [478/527] Processing volume...\n",
      "training: [479/527] Processing volume...\n",
      "training: [480/527] Processing volume...\n",
      "training: [481/527] Processing volume...\n",
      "training: [482/527] Processing volume...\n",
      "training: [483/527] Processing volume...\n",
      "training: [484/527] Processing volume...\n",
      "training: [485/527] Processing volume...\n",
      "validation step in training epoch 2\n",
      "aorta dissection not manually set, use the value in csv file\n",
      "original image shape: torch.Size([1, 1, 512, 512, 89])\n",
      "inference val set from 10 to 10 batch\n",
      "validation: [1/2] Processing volume...\n",
      "patient ID: 1PC078\n",
      "input volume shape: torch.Size([1, 512, 512, 89])\n",
      "target volume shape: torch.Size([1, 512, 512, 89])\n",
      "ad: tensor(0)\n",
      "modality: tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: [2/2] Processing volume...\n",
      "patient ID: 42025705_4\n",
      "input volume shape: torch.Size([1, 512, 512, 39])\n",
      "target volume shape: torch.Size([1, 512, 512, 39])\n",
      "ad: tensor(0)\n",
      "modality: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: [486/527] Processing volume...\n",
      "training: [487/527] Processing volume...\n",
      "training: [488/527] Processing volume...\n",
      "training: [489/527] Processing volume...\n",
      "training: [490/527] Processing volume...\n",
      "training: [491/527] Processing volume...\n",
      "training: [492/527] Processing volume...\n",
      "training: [493/527] Processing volume...\n",
      "training: [494/527] Processing volume...\n",
      "training: [495/527] Processing volume...\n",
      "training: [496/527] Processing volume...\n",
      "training: [497/527] Processing volume...\n",
      "training: [498/527] Processing volume...\n",
      "training: [499/527] Processing volume...\n",
      "training: [500/527] Processing volume...\n",
      "training: [501/527] Processing volume...\n",
      "training: [502/527] Processing volume...\n",
      "training: [503/527] Processing volume...\n",
      "validation step in training epoch 2\n",
      "aorta dissection not manually set, use the value in csv file\n",
      "original image shape: torch.Size([1, 1, 512, 512, 89])\n",
      "inference val set from 10 to 10 batch\n",
      "validation: [1/2] Processing volume...\n",
      "patient ID: 1PC078\n",
      "input volume shape: torch.Size([1, 512, 512, 89])\n",
      "target volume shape: torch.Size([1, 512, 512, 89])\n",
      "ad: tensor(0)\n",
      "modality: tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: [2/2] Processing volume...\n",
      "patient ID: 42025705_4\n",
      "input volume shape: torch.Size([1, 512, 512, 39])\n",
      "target volume shape: torch.Size([1, 512, 512, 39])\n",
      "ad: tensor(0)\n",
      "modality: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: [504/527] Processing volume...\n",
      "training: [505/527] Processing volume...\n",
      "training: [506/527] Processing volume...\n",
      "training: [507/527] Processing volume...\n",
      "training: [508/527] Processing volume...\n",
      "training: [509/527] Processing volume...\n",
      "training: [510/527] Processing volume...\n",
      "training: [511/527] Processing volume...\n",
      "training: [512/527] Processing volume...\n",
      "training: [513/527] Processing volume...\n",
      "training: [514/527] Processing volume...\n",
      "training: [515/527] Processing volume...\n",
      "training: [516/527] Processing volume...\n",
      "training: [517/527] Processing volume...\n",
      "training: [518/527] Processing volume...\n",
      "training: [519/527] Processing volume...\n",
      "training: [520/527] Processing volume...\n",
      "training: [521/527] Processing volume...\n",
      "validation step in training epoch 2\n",
      "aorta dissection not manually set, use the value in csv file\n",
      "original image shape: torch.Size([1, 1, 512, 512, 89])\n",
      "inference val set from 10 to 10 batch\n",
      "validation: [1/2] Processing volume...\n",
      "patient ID: 1PC078\n",
      "input volume shape: torch.Size([1, 512, 512, 89])\n",
      "target volume shape: torch.Size([1, 512, 512, 89])\n",
      "ad: tensor(0)\n",
      "modality: tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: [2/2] Processing volume...\n",
      "patient ID: 42025705_4\n",
      "input volume shape: torch.Size([1, 512, 512, 39])\n",
      "target volume shape: torch.Size([1, 512, 512, 39])\n",
      "ad: tensor(0)\n",
      "modality: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: [522/527] Processing volume...\n",
      "training: [523/527] Processing volume...\n",
      "training: [524/527] Processing volume...\n",
      "training: [525/527] Processing volume...\n",
      "training: [526/527] Processing volume...\n",
      "training: [527/527] Processing volume...\n",
      "validation step in training epoch 2\n",
      "aorta dissection not manually set, use the value in csv file\n",
      "original image shape: torch.Size([1, 1, 512, 512, 89])\n",
      "inference val set from 10 to 10 batch\n",
      "validation: [1/2] Processing volume...\n",
      "patient ID: 1PC078\n",
      "input volume shape: torch.Size([1, 512, 512, 89])\n",
      "target volume shape: torch.Size([1, 512, 512, 89])\n",
      "ad: tensor(0)\n",
      "modality: tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: [2/2] Processing volume...\n",
      "patient ID: 42025705_4\n",
      "input volume shape: torch.Size([1, 512, 512, 39])\n",
      "target volume shape: torch.Size([1, 512, 512, 39])\n",
      "ad: tensor(0)\n",
      "modality: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss updated, value:  1.1337173279317756\n",
      "original image shape: torch.Size([1, 1, 512, 512, 149])\n",
      "training: [1/527] Processing volume...\n",
      "training: [2/527] Processing volume...\n",
      "training: [3/527] Processing volume...\n",
      "training: [4/527] Processing volume...\n",
      "training: [5/527] Processing volume...\n",
      "training: [6/527] Processing volume...\n",
      "training: [7/527] Processing volume...\n",
      "training: [8/527] Processing volume...\n",
      "training: [9/527] Processing volume...\n",
      "training: [10/527] Processing volume...\n",
      "training: [11/527] Processing volume...\n",
      "training: [12/527] Processing volume...\n",
      "training: [13/527] Processing volume...\n",
      "training: [14/527] Processing volume...\n",
      "training: [15/527] Processing volume...\n",
      "training: [16/527] Processing volume...\n",
      "training: [17/527] Processing volume...\n",
      "training: [18/527] Processing volume...\n",
      "training: [19/527] Processing volume...\n",
      "training: [20/527] Processing volume...\n",
      "training: [21/527] Processing volume...\n",
      "training: [22/527] Processing volume...\n",
      "validation step in training epoch 3\n",
      "aorta dissection not manually set, use the value in csv file\n",
      "original image shape: torch.Size([1, 1, 512, 512, 89])\n",
      "inference val set from 10 to 10 batch\n",
      "validation: [1/2] Processing volume...\n",
      "patient ID: 1PC078\n",
      "input volume shape: torch.Size([1, 512, 512, 89])\n",
      "target volume shape: torch.Size([1, 512, 512, 89])\n",
      "ad: tensor(0)\n",
      "modality: tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: [2/2] Processing volume...\n",
      "patient ID: 42025705_4\n",
      "input volume shape: torch.Size([1, 512, 512, 39])\n",
      "target volume shape: torch.Size([1, 512, 512, 39])\n",
      "ad: tensor(0)\n",
      "modality: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: [23/527] Processing volume...\n",
      "training: [24/527] Processing volume...\n",
      "training: [25/527] Processing volume...\n",
      "training: [26/527] Processing volume...\n",
      "training: [27/527] Processing volume...\n",
      "training: [28/527] Processing volume...\n",
      "training: [29/527] Processing volume...\n",
      "training: [30/527] Processing volume...\n",
      "training: [31/527] Processing volume...\n",
      "training: [32/527] Processing volume...\n",
      "training: [33/527] Processing volume...\n",
      "training: [34/527] Processing volume...\n",
      "training: [35/527] Processing volume...\n",
      "training: [36/527] Processing volume...\n",
      "training: [37/527] Processing volume...\n",
      "training: [38/527] Processing volume...\n",
      "training: [39/527] Processing volume...\n",
      "training: [40/527] Processing volume...\n",
      "training: [41/527] Processing volume...\n",
      "training: [42/527] Processing volume...\n",
      "training: [43/527] Processing volume...\n",
      "training: [44/527] Processing volume...\n",
      "training: [45/527] Processing volume...\n",
      "training: [46/527] Processing volume...\n",
      "training: [47/527] Processing volume...\n",
      "training: [48/527] Processing volume...\n",
      "training: [49/527] Processing volume...\n",
      "training: [50/527] Processing volume...\n",
      "training: [51/527] Processing volume...\n",
      "training: [52/527] Processing volume...\n",
      "training: [53/527] Processing volume...\n",
      "training: [54/527] Processing volume...\n",
      "training: [55/527] Processing volume...\n",
      "validation step in training epoch 3\n",
      "aorta dissection not manually set, use the value in csv file\n",
      "original image shape: torch.Size([1, 1, 512, 512, 89])\n",
      "inference val set from 10 to 10 batch\n",
      "validation: [1/2] Processing volume...\n",
      "patient ID: 1PC078\n",
      "input volume shape: torch.Size([1, 512, 512, 89])\n",
      "target volume shape: torch.Size([1, 512, 512, 89])\n",
      "ad: tensor(0)\n",
      "modality: tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: [2/2] Processing volume...\n",
      "patient ID: 42025705_4\n",
      "input volume shape: torch.Size([1, 512, 512, 39])\n",
      "target volume shape: torch.Size([1, 512, 512, 39])\n",
      "ad: tensor(0)\n",
      "modality: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: [56/527] Processing volume...\n",
      "training: [57/527] Processing volume...\n",
      "training: [58/527] Processing volume...\n",
      "training: [59/527] Processing volume...\n",
      "training: [60/527] Processing volume...\n",
      "training: [61/527] Processing volume...\n",
      "training: [62/527] Processing volume...\n",
      "training: [63/527] Processing volume...\n",
      "training: [64/527] Processing volume...\n",
      "training: [65/527] Processing volume...\n",
      "training: [66/527] Processing volume...\n",
      "training: [67/527] Processing volume...\n",
      "training: [68/527] Processing volume...\n",
      "training: [69/527] Processing volume...\n",
      "training: [70/527] Processing volume...\n",
      "training: [71/527] Processing volume...\n",
      "training: [72/527] Processing volume...\n",
      "training: [73/527] Processing volume...\n",
      "training: [74/527] Processing volume...\n",
      "training: [75/527] Processing volume...\n",
      "training: [76/527] Processing volume...\n",
      "training: [77/527] Processing volume...\n",
      "training: [78/527] Processing volume...\n",
      "training: [79/527] Processing volume...\n",
      "training: [80/527] Processing volume...\n",
      "training: [81/527] Processing volume...\n",
      "training: [82/527] Processing volume...\n",
      "training: [83/527] Processing volume...\n",
      "training: [84/527] Processing volume...\n",
      "training: [85/527] Processing volume...\n",
      "training: [86/527] Processing volume...\n",
      "training: [87/527] Processing volume...\n",
      "training: [88/527] Processing volume...\n",
      "training: [89/527] Processing volume...\n",
      "validation step in training epoch 3\n",
      "aorta dissection not manually set, use the value in csv file\n",
      "original image shape: torch.Size([1, 1, 512, 512, 89])\n",
      "inference val set from 10 to 10 batch\n",
      "validation: [1/2] Processing volume...\n",
      "patient ID: 1PC078\n",
      "input volume shape: torch.Size([1, 512, 512, 89])\n",
      "target volume shape: torch.Size([1, 512, 512, 89])\n",
      "ad: tensor(0)\n",
      "modality: tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 12.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: [2/2] Processing volume...\n",
      "patient ID: 42025705_4\n",
      "input volume shape: torch.Size([1, 512, 512, 39])\n",
      "target volume shape: torch.Size([1, 512, 512, 39])\n",
      "ad: tensor(0)\n",
      "modality: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: [90/527] Processing volume...\n",
      "training: [91/527] Processing volume...\n",
      "training: [92/527] Processing volume...\n",
      "training: [93/527] Processing volume...\n",
      "training: [94/527] Processing volume...\n",
      "training: [95/527] Processing volume...\n",
      "training: [96/527] Processing volume...\n",
      "training: [97/527] Processing volume...\n",
      "training: [98/527] Processing volume...\n",
      "training: [99/527] Processing volume...\n",
      "training: [100/527] Processing volume...\n",
      "training: [101/527] Processing volume...\n",
      "training: [102/527] Processing volume...\n",
      "training: [103/527] Processing volume...\n",
      "training: [104/527] Processing volume...\n",
      "training: [105/527] Processing volume...\n",
      "training: [106/527] Processing volume...\n",
      "training: [107/527] Processing volume...\n",
      "training: [108/527] Processing volume...\n",
      "training: [109/527] Processing volume...\n",
      "training: [110/527] Processing volume...\n",
      "training: [111/527] Processing volume...\n",
      "training: [112/527] Processing volume...\n",
      "training: [113/527] Processing volume...\n",
      "training: [114/527] Processing volume...\n",
      "training: [115/527] Processing volume...\n",
      "training: [116/527] Processing volume...\n",
      "training: [117/527] Processing volume...\n",
      "training: [118/527] Processing volume...\n",
      "training: [119/527] Processing volume...\n",
      "training: [120/527] Processing volume...\n",
      "training: [121/527] Processing volume...\n",
      "training: [122/527] Processing volume...\n",
      "validation step in training epoch 3\n",
      "aorta dissection not manually set, use the value in csv file\n",
      "original image shape: torch.Size([1, 1, 512, 512, 89])\n",
      "inference val set from 10 to 10 batch\n",
      "validation: [1/2] Processing volume...\n",
      "patient ID: 1PC078\n",
      "input volume shape: torch.Size([1, 512, 512, 89])\n",
      "target volume shape: torch.Size([1, 512, 512, 89])\n",
      "ad: tensor(0)\n",
      "modality: tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: [2/2] Processing volume...\n",
      "patient ID: 42025705_4\n",
      "input volume shape: torch.Size([1, 512, 512, 39])\n",
      "target volume shape: torch.Size([1, 512, 512, 39])\n",
      "ad: tensor(0)\n",
      "modality: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: [123/527] Processing volume...\n",
      "training: [124/527] Processing volume...\n",
      "training: [125/527] Processing volume...\n",
      "training: [126/527] Processing volume...\n",
      "training: [127/527] Processing volume...\n",
      "training: [128/527] Processing volume...\n",
      "training: [129/527] Processing volume...\n",
      "training: [130/527] Processing volume...\n",
      "training: [131/527] Processing volume...\n",
      "training: [132/527] Processing volume...\n",
      "training: [133/527] Processing volume...\n",
      "training: [134/527] Processing volume...\n",
      "training: [135/527] Processing volume...\n",
      "training: [136/527] Processing volume...\n",
      "training: [137/527] Processing volume...\n",
      "training: [138/527] Processing volume...\n",
      "training: [139/527] Processing volume...\n",
      "training: [140/527] Processing volume...\n",
      "training: [141/527] Processing volume...\n",
      "training: [142/527] Processing volume...\n",
      "training: [143/527] Processing volume...\n",
      "training: [144/527] Processing volume...\n",
      "training: [145/527] Processing volume...\n",
      "training: [146/527] Processing volume...\n",
      "training: [147/527] Processing volume...\n",
      "training: [148/527] Processing volume...\n",
      "training: [149/527] Processing volume...\n",
      "training: [150/527] Processing volume...\n",
      "training: [151/527] Processing volume...\n",
      "training: [152/527] Processing volume...\n",
      "training: [153/527] Processing volume...\n",
      "training: [154/527] Processing volume...\n",
      "training: [155/527] Processing volume...\n",
      "training: [156/527] Processing volume...\n",
      "validation step in training epoch 3\n",
      "aorta dissection not manually set, use the value in csv file\n",
      "original image shape: torch.Size([1, 1, 512, 512, 89])\n",
      "inference val set from 10 to 10 batch\n",
      "validation: [1/2] Processing volume...\n",
      "patient ID: 1PC078\n",
      "input volume shape: torch.Size([1, 512, 512, 89])\n",
      "target volume shape: torch.Size([1, 512, 512, 89])\n",
      "ad: tensor(0)\n",
      "modality: tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: [2/2] Processing volume...\n",
      "patient ID: 42025705_4\n",
      "input volume shape: torch.Size([1, 512, 512, 39])\n",
      "target volume shape: torch.Size([1, 512, 512, 39])\n",
      "ad: tensor(0)\n",
      "modality: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: [157/527] Processing volume...\n",
      "training: [158/527] Processing volume...\n",
      "training: [159/527] Processing volume...\n",
      "training: [160/527] Processing volume...\n",
      "training: [161/527] Processing volume...\n",
      "training: [162/527] Processing volume...\n",
      "training: [163/527] Processing volume...\n",
      "training: [164/527] Processing volume...\n",
      "training: [165/527] Processing volume...\n",
      "training: [166/527] Processing volume...\n",
      "training: [167/527] Processing volume...\n",
      "training: [168/527] Processing volume...\n",
      "training: [169/527] Processing volume...\n",
      "training: [170/527] Processing volume...\n",
      "training: [171/527] Processing volume...\n",
      "training: [172/527] Processing volume...\n",
      "training: [173/527] Processing volume...\n",
      "training: [174/527] Processing volume...\n",
      "training: [175/527] Processing volume...\n",
      "training: [176/527] Processing volume...\n",
      "training: [177/527] Processing volume...\n",
      "training: [178/527] Processing volume...\n",
      "training: [179/527] Processing volume...\n",
      "training: [180/527] Processing volume...\n",
      "training: [181/527] Processing volume...\n",
      "training: [182/527] Processing volume...\n",
      "training: [183/527] Processing volume...\n",
      "training: [184/527] Processing volume...\n",
      "training: [185/527] Processing volume...\n",
      "training: [186/527] Processing volume...\n",
      "training: [187/527] Processing volume...\n",
      "validation step in training epoch 3\n",
      "aorta dissection not manually set, use the value in csv file\n",
      "original image shape: torch.Size([1, 1, 512, 512, 89])\n",
      "inference val set from 10 to 10 batch\n",
      "validation: [1/2] Processing volume...\n",
      "patient ID: 1PC078\n",
      "input volume shape: torch.Size([1, 512, 512, 89])\n",
      "target volume shape: torch.Size([1, 512, 512, 89])\n",
      "ad: tensor(0)\n",
      "modality: tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:42<00:00, 11.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: [2/2] Processing volume...\n",
      "patient ID: 42025705_4\n",
      "input volume shape: torch.Size([1, 512, 512, 39])\n",
      "target volume shape: torch.Size([1, 512, 512, 39])\n",
      "ad: tensor(0)\n",
      "modality: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:42<00:00, 11.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: [188/527] Processing volume...\n",
      "training: [189/527] Processing volume...\n",
      "training: [190/527] Processing volume...\n",
      "training: [191/527] Processing volume...\n",
      "training: [192/527] Processing volume...\n",
      "training: [193/527] Processing volume...\n",
      "training: [194/527] Processing volume...\n",
      "training: [195/527] Processing volume...\n",
      "training: [196/527] Processing volume...\n",
      "training: [197/527] Processing volume...\n",
      "training: [198/527] Processing volume...\n",
      "training: [199/527] Processing volume...\n",
      "training: [200/527] Processing volume...\n",
      "training: [201/527] Processing volume...\n",
      "training: [202/527] Processing volume...\n",
      "training: [203/527] Processing volume...\n",
      "training: [204/527] Processing volume...\n",
      "training: [205/527] Processing volume...\n",
      "training: [206/527] Processing volume...\n",
      "training: [207/527] Processing volume...\n",
      "training: [208/527] Processing volume...\n",
      "training: [209/527] Processing volume...\n",
      "training: [210/527] Processing volume...\n",
      "training: [211/527] Processing volume...\n",
      "training: [212/527] Processing volume...\n",
      "training: [213/527] Processing volume...\n",
      "training: [214/527] Processing volume...\n",
      "training: [215/527] Processing volume...\n",
      "training: [216/527] Processing volume...\n",
      "training: [217/527] Processing volume...\n",
      "validation step in training epoch 3\n",
      "aorta dissection not manually set, use the value in csv file\n",
      "original image shape: torch.Size([1, 1, 512, 512, 89])\n",
      "inference val set from 10 to 10 batch\n",
      "validation: [1/2] Processing volume...\n",
      "patient ID: 1PC078\n",
      "input volume shape: torch.Size([1, 512, 512, 89])\n",
      "target volume shape: torch.Size([1, 512, 512, 89])\n",
      "ad: tensor(0)\n",
      "modality: tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:42<00:00, 11.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: [2/2] Processing volume...\n",
      "patient ID: 42025705_4\n",
      "input volume shape: torch.Size([1, 512, 512, 39])\n",
      "target volume shape: torch.Size([1, 512, 512, 39])\n",
      "ad: tensor(0)\n",
      "modality: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:42<00:00, 11.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: [218/527] Processing volume...\n",
      "training: [219/527] Processing volume...\n",
      "training: [220/527] Processing volume...\n",
      "training: [221/527] Processing volume...\n",
      "training: [222/527] Processing volume...\n",
      "training: [223/527] Processing volume...\n",
      "training: [224/527] Processing volume...\n",
      "training: [225/527] Processing volume...\n",
      "training: [226/527] Processing volume...\n",
      "training: [227/527] Processing volume...\n",
      "training: [228/527] Processing volume...\n",
      "training: [229/527] Processing volume...\n",
      "training: [230/527] Processing volume...\n",
      "training: [231/527] Processing volume...\n",
      "training: [232/527] Processing volume...\n",
      "training: [233/527] Processing volume...\n",
      "training: [234/527] Processing volume...\n",
      "training: [235/527] Processing volume...\n",
      "training: [236/527] Processing volume...\n",
      "training: [237/527] Processing volume...\n",
      "training: [238/527] Processing volume...\n",
      "training: [239/527] Processing volume...\n",
      "training: [240/527] Processing volume...\n",
      "training: [241/527] Processing volume...\n",
      "training: [242/527] Processing volume...\n",
      "training: [243/527] Processing volume...\n",
      "training: [244/527] Processing volume...\n",
      "training: [245/527] Processing volume...\n",
      "training: [246/527] Processing volume...\n",
      "training: [247/527] Processing volume...\n",
      "training: [248/527] Processing volume...\n",
      "training: [249/527] Processing volume...\n",
      "training: [250/527] Processing volume...\n",
      "training: [251/527] Processing volume...\n",
      "validation step in training epoch 3\n",
      "aorta dissection not manually set, use the value in csv file\n",
      "original image shape: torch.Size([1, 1, 512, 512, 89])\n",
      "inference val set from 10 to 10 batch\n",
      "validation: [1/2] Processing volume...\n",
      "patient ID: 1PC078\n",
      "input volume shape: torch.Size([1, 512, 512, 89])\n",
      "target volume shape: torch.Size([1, 512, 512, 89])\n",
      "ad: tensor(0)\n",
      "modality: tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:42<00:00, 11.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: [2/2] Processing volume...\n",
      "patient ID: 42025705_4\n",
      "input volume shape: torch.Size([1, 512, 512, 39])\n",
      "target volume shape: torch.Size([1, 512, 512, 39])\n",
      "ad: tensor(0)\n",
      "modality: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:42<00:00, 11.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: [252/527] Processing volume...\n",
      "training: [253/527] Processing volume...\n",
      "training: [254/527] Processing volume...\n",
      "training: [255/527] Processing volume...\n",
      "training: [256/527] Processing volume...\n",
      "training: [257/527] Processing volume...\n",
      "training: [258/527] Processing volume...\n",
      "training: [259/527] Processing volume...\n",
      "training: [260/527] Processing volume...\n",
      "training: [261/527] Processing volume...\n",
      "training: [262/527] Processing volume...\n",
      "training: [263/527] Processing volume...\n",
      "training: [264/527] Processing volume...\n",
      "training: [265/527] Processing volume...\n",
      "training: [266/527] Processing volume...\n",
      "training: [267/527] Processing volume...\n",
      "training: [268/527] Processing volume...\n",
      "training: [269/527] Processing volume...\n",
      "training: [270/527] Processing volume...\n",
      "training: [271/527] Processing volume...\n",
      "training: [272/527] Processing volume...\n",
      "training: [273/527] Processing volume...\n",
      "training: [274/527] Processing volume...\n",
      "training: [275/527] Processing volume...\n",
      "training: [276/527] Processing volume...\n",
      "training: [277/527] Processing volume...\n",
      "training: [278/527] Processing volume...\n",
      "training: [279/527] Processing volume...\n",
      "training: [280/527] Processing volume...\n",
      "training: [281/527] Processing volume...\n",
      "training: [282/527] Processing volume...\n",
      "training: [283/527] Processing volume...\n",
      "training: [284/527] Processing volume...\n",
      "training: [285/527] Processing volume...\n",
      "training: [286/527] Processing volume...\n",
      "training: [287/527] Processing volume...\n",
      "training: [288/527] Processing volume...\n",
      "training: [289/527] Processing volume...\n",
      "training: [290/527] Processing volume...\n",
      "training: [291/527] Processing volume...\n",
      "training: [292/527] Processing volume...\n",
      "training: [293/527] Processing volume...\n",
      "training: [294/527] Processing volume...\n",
      "training: [295/527] Processing volume...\n",
      "training: [296/527] Processing volume...\n",
      "training: [297/527] Processing volume...\n",
      "training: [298/527] Processing volume...\n",
      "validation step in training epoch 3\n",
      "aorta dissection not manually set, use the value in csv file\n",
      "original image shape: torch.Size([1, 1, 512, 512, 89])\n",
      "inference val set from 10 to 10 batch\n",
      "validation: [1/2] Processing volume...\n",
      "patient ID: 1PC078\n",
      "input volume shape: torch.Size([1, 512, 512, 89])\n",
      "target volume shape: torch.Size([1, 512, 512, 89])\n",
      "ad: tensor(0)\n",
      "modality: tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:42<00:00, 11.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: [2/2] Processing volume...\n",
      "patient ID: 42025705_4\n",
      "input volume shape: torch.Size([1, 512, 512, 39])\n",
      "target volume shape: torch.Size([1, 512, 512, 39])\n",
      "ad: tensor(0)\n",
      "modality: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:42<00:00, 11.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: [299/527] Processing volume...\n",
      "training: [300/527] Processing volume...\n",
      "training: [301/527] Processing volume...\n",
      "training: [302/527] Processing volume...\n",
      "training: [303/527] Processing volume...\n",
      "training: [304/527] Processing volume...\n",
      "training: [305/527] Processing volume...\n",
      "training: [306/527] Processing volume...\n",
      "training: [307/527] Processing volume...\n",
      "training: [308/527] Processing volume...\n",
      "training: [309/527] Processing volume...\n",
      "training: [310/527] Processing volume...\n",
      "training: [311/527] Processing volume...\n",
      "training: [312/527] Processing volume...\n",
      "training: [313/527] Processing volume...\n",
      "training: [314/527] Processing volume...\n",
      "training: [315/527] Processing volume...\n",
      "training: [316/527] Processing volume...\n",
      "training: [317/527] Processing volume...\n",
      "training: [318/527] Processing volume...\n",
      "training: [319/527] Processing volume...\n",
      "training: [320/527] Processing volume...\n",
      "training: [321/527] Processing volume...\n",
      "training: [322/527] Processing volume...\n",
      "training: [323/527] Processing volume...\n",
      "training: [324/527] Processing volume...\n",
      "training: [325/527] Processing volume...\n",
      "training: [326/527] Processing volume...\n",
      "training: [327/527] Processing volume...\n",
      "training: [328/527] Processing volume...\n",
      "training: [329/527] Processing volume...\n",
      "training: [330/527] Processing volume...\n",
      "training: [331/527] Processing volume...\n",
      "training: [332/527] Processing volume...\n",
      "training: [333/527] Processing volume...\n",
      "training: [334/527] Processing volume...\n",
      "training: [335/527] Processing volume...\n",
      "training: [336/527] Processing volume...\n",
      "training: [337/527] Processing volume...\n",
      "training: [338/527] Processing volume...\n",
      "training: [339/527] Processing volume...\n",
      "training: [340/527] Processing volume...\n",
      "training: [341/527] Processing volume...\n",
      "training: [342/527] Processing volume...\n",
      "training: [343/527] Processing volume...\n",
      "training: [344/527] Processing volume...\n",
      "training: [345/527] Processing volume...\n",
      "training: [346/527] Processing volume...\n",
      "training: [347/527] Processing volume...\n",
      "training: [348/527] Processing volume...\n",
      "training: [349/527] Processing volume...\n",
      "training: [350/527] Processing volume...\n",
      "training: [351/527] Processing volume...\n",
      "training: [352/527] Processing volume...\n",
      "training: [353/527] Processing volume...\n",
      "training: [354/527] Processing volume...\n",
      "validation step in training epoch 3\n",
      "aorta dissection not manually set, use the value in csv file\n",
      "original image shape: torch.Size([1, 1, 512, 512, 89])\n",
      "inference val set from 10 to 10 batch\n",
      "validation: [1/2] Processing volume...\n",
      "patient ID: 1PC078\n",
      "input volume shape: torch.Size([1, 512, 512, 89])\n",
      "target volume shape: torch.Size([1, 512, 512, 89])\n",
      "ad: tensor(0)\n",
      "modality: tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: [2/2] Processing volume...\n",
      "patient ID: 42025705_4\n",
      "input volume shape: torch.Size([1, 512, 512, 39])\n",
      "target volume shape: torch.Size([1, 512, 512, 39])\n",
      "ad: tensor(0)\n",
      "modality: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: [355/527] Processing volume...\n",
      "training: [356/527] Processing volume...\n",
      "training: [357/527] Processing volume...\n",
      "training: [358/527] Processing volume...\n",
      "training: [359/527] Processing volume...\n",
      "training: [360/527] Processing volume...\n",
      "training: [361/527] Processing volume...\n",
      "training: [362/527] Processing volume...\n",
      "training: [363/527] Processing volume...\n",
      "training: [364/527] Processing volume...\n",
      "training: [365/527] Processing volume...\n",
      "training: [366/527] Processing volume...\n",
      "training: [367/527] Processing volume...\n",
      "training: [368/527] Processing volume...\n",
      "training: [369/527] Processing volume...\n",
      "training: [370/527] Processing volume...\n",
      "training: [371/527] Processing volume...\n",
      "training: [372/527] Processing volume...\n",
      "training: [373/527] Processing volume...\n",
      "training: [374/527] Processing volume...\n",
      "training: [375/527] Processing volume...\n",
      "training: [376/527] Processing volume...\n",
      "training: [377/527] Processing volume...\n",
      "training: [378/527] Processing volume...\n",
      "training: [379/527] Processing volume...\n",
      "training: [380/527] Processing volume...\n",
      "training: [381/527] Processing volume...\n",
      "training: [382/527] Processing volume...\n",
      "training: [383/527] Processing volume...\n",
      "training: [384/527] Processing volume...\n",
      "training: [385/527] Processing volume...\n",
      "training: [386/527] Processing volume...\n",
      "training: [387/527] Processing volume...\n",
      "training: [388/527] Processing volume...\n",
      "training: [389/527] Processing volume...\n",
      "training: [390/527] Processing volume...\n",
      "training: [391/527] Processing volume...\n",
      "training: [392/527] Processing volume...\n",
      "training: [393/527] Processing volume...\n",
      "training: [394/527] Processing volume...\n",
      "training: [395/527] Processing volume...\n",
      "training: [396/527] Processing volume...\n",
      "training: [397/527] Processing volume...\n",
      "training: [398/527] Processing volume...\n",
      "training: [399/527] Processing volume...\n",
      "training: [400/527] Processing volume...\n",
      "training: [401/527] Processing volume...\n",
      "training: [402/527] Processing volume...\n",
      "validation step in training epoch 3\n",
      "aorta dissection not manually set, use the value in csv file\n",
      "original image shape: torch.Size([1, 1, 512, 512, 89])\n",
      "inference val set from 10 to 10 batch\n",
      "validation: [1/2] Processing volume...\n",
      "patient ID: 1PC078\n",
      "input volume shape: torch.Size([1, 512, 512, 89])\n",
      "target volume shape: torch.Size([1, 512, 512, 89])\n",
      "ad: tensor(0)\n",
      "modality: tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: [2/2] Processing volume...\n",
      "patient ID: 42025705_4\n",
      "input volume shape: torch.Size([1, 512, 512, 39])\n",
      "target volume shape: torch.Size([1, 512, 512, 39])\n",
      "ad: tensor(0)\n",
      "modality: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: [403/527] Processing volume...\n",
      "training: [404/527] Processing volume...\n",
      "training: [405/527] Processing volume...\n",
      "training: [406/527] Processing volume...\n",
      "training: [407/527] Processing volume...\n",
      "training: [408/527] Processing volume...\n",
      "training: [409/527] Processing volume...\n",
      "training: [410/527] Processing volume...\n",
      "training: [411/527] Processing volume...\n",
      "training: [412/527] Processing volume...\n",
      "training: [413/527] Processing volume...\n",
      "training: [414/527] Processing volume...\n",
      "training: [415/527] Processing volume...\n",
      "training: [416/527] Processing volume...\n",
      "training: [417/527] Processing volume...\n",
      "training: [418/527] Processing volume...\n",
      "training: [419/527] Processing volume...\n",
      "training: [420/527] Processing volume...\n",
      "validation step in training epoch 3\n",
      "aorta dissection not manually set, use the value in csv file\n",
      "original image shape: torch.Size([1, 1, 512, 512, 89])\n",
      "inference val set from 10 to 10 batch\n",
      "validation: [1/2] Processing volume...\n",
      "patient ID: 1PC078\n",
      "input volume shape: torch.Size([1, 512, 512, 89])\n",
      "target volume shape: torch.Size([1, 512, 512, 89])\n",
      "ad: tensor(0)\n",
      "modality: tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: [2/2] Processing volume...\n",
      "patient ID: 42025705_4\n",
      "input volume shape: torch.Size([1, 512, 512, 39])\n",
      "target volume shape: torch.Size([1, 512, 512, 39])\n",
      "ad: tensor(0)\n",
      "modality: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: [421/527] Processing volume...\n",
      "training: [422/527] Processing volume...\n",
      "training: [423/527] Processing volume...\n",
      "training: [424/527] Processing volume...\n",
      "training: [425/527] Processing volume...\n",
      "training: [426/527] Processing volume...\n",
      "training: [427/527] Processing volume...\n",
      "training: [428/527] Processing volume...\n",
      "training: [429/527] Processing volume...\n",
      "training: [430/527] Processing volume...\n",
      "training: [431/527] Processing volume...\n",
      "training: [432/527] Processing volume...\n",
      "training: [433/527] Processing volume...\n",
      "training: [434/527] Processing volume...\n",
      "training: [435/527] Processing volume...\n",
      "training: [436/527] Processing volume...\n",
      "training: [437/527] Processing volume...\n",
      "validation step in training epoch 3\n",
      "aorta dissection not manually set, use the value in csv file\n",
      "original image shape: torch.Size([1, 1, 512, 512, 89])\n",
      "inference val set from 10 to 10 batch\n",
      "validation: [1/2] Processing volume...\n",
      "patient ID: 1PC078\n",
      "input volume shape: torch.Size([1, 512, 512, 89])\n",
      "target volume shape: torch.Size([1, 512, 512, 89])\n",
      "ad: tensor(0)\n",
      "modality: tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: [2/2] Processing volume...\n",
      "patient ID: 42025705_4\n",
      "input volume shape: torch.Size([1, 512, 512, 39])\n",
      "target volume shape: torch.Size([1, 512, 512, 39])\n",
      "ad: tensor(0)\n",
      "modality: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: [438/527] Processing volume...\n",
      "training: [439/527] Processing volume...\n",
      "training: [440/527] Processing volume...\n",
      "training: [441/527] Processing volume...\n",
      "training: [442/527] Processing volume...\n",
      "training: [443/527] Processing volume...\n",
      "training: [444/527] Processing volume...\n",
      "training: [445/527] Processing volume...\n",
      "training: [446/527] Processing volume...\n",
      "training: [447/527] Processing volume...\n",
      "training: [448/527] Processing volume...\n",
      "training: [449/527] Processing volume...\n",
      "training: [450/527] Processing volume...\n",
      "training: [451/527] Processing volume...\n",
      "training: [452/527] Processing volume...\n",
      "training: [453/527] Processing volume...\n",
      "training: [454/527] Processing volume...\n",
      "training: [455/527] Processing volume...\n",
      "validation step in training epoch 3\n",
      "aorta dissection not manually set, use the value in csv file\n",
      "original image shape: torch.Size([1, 1, 512, 512, 89])\n",
      "inference val set from 10 to 10 batch\n",
      "validation: [1/2] Processing volume...\n",
      "patient ID: 1PC078\n",
      "input volume shape: torch.Size([1, 512, 512, 89])\n",
      "target volume shape: torch.Size([1, 512, 512, 89])\n",
      "ad: tensor(0)\n",
      "modality: tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: [2/2] Processing volume...\n",
      "patient ID: 42025705_4\n",
      "input volume shape: torch.Size([1, 512, 512, 39])\n",
      "target volume shape: torch.Size([1, 512, 512, 39])\n",
      "ad: tensor(0)\n",
      "modality: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: [456/527] Processing volume...\n",
      "training: [457/527] Processing volume...\n",
      "training: [458/527] Processing volume...\n",
      "training: [459/527] Processing volume...\n",
      "training: [460/527] Processing volume...\n",
      "training: [461/527] Processing volume...\n",
      "training: [462/527] Processing volume...\n",
      "training: [463/527] Processing volume...\n",
      "training: [464/527] Processing volume...\n",
      "training: [465/527] Processing volume...\n",
      "training: [466/527] Processing volume...\n",
      "training: [467/527] Processing volume...\n",
      "training: [468/527] Processing volume...\n",
      "training: [469/527] Processing volume...\n",
      "training: [470/527] Processing volume...\n",
      "training: [471/527] Processing volume...\n",
      "training: [472/527] Processing volume...\n",
      "training: [473/527] Processing volume...\n",
      "validation step in training epoch 3\n",
      "aorta dissection not manually set, use the value in csv file\n",
      "original image shape: torch.Size([1, 1, 512, 512, 89])\n",
      "inference val set from 10 to 10 batch\n",
      "validation: [1/2] Processing volume...\n",
      "patient ID: 1PC078\n",
      "input volume shape: torch.Size([1, 512, 512, 89])\n",
      "target volume shape: torch.Size([1, 512, 512, 89])\n",
      "ad: tensor(0)\n",
      "modality: tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: [2/2] Processing volume...\n",
      "patient ID: 42025705_4\n",
      "input volume shape: torch.Size([1, 512, 512, 39])\n",
      "target volume shape: torch.Size([1, 512, 512, 39])\n",
      "ad: tensor(0)\n",
      "modality: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: [474/527] Processing volume...\n",
      "training: [475/527] Processing volume...\n",
      "training: [476/527] Processing volume...\n",
      "training: [477/527] Processing volume...\n",
      "training: [478/527] Processing volume...\n",
      "training: [479/527] Processing volume...\n",
      "training: [480/527] Processing volume...\n",
      "training: [481/527] Processing volume...\n",
      "training: [482/527] Processing volume...\n",
      "training: [483/527] Processing volume...\n",
      "training: [484/527] Processing volume...\n",
      "training: [485/527] Processing volume...\n",
      "training: [486/527] Processing volume...\n",
      "training: [487/527] Processing volume...\n",
      "training: [488/527] Processing volume...\n",
      "training: [489/527] Processing volume...\n",
      "training: [490/527] Processing volume...\n",
      "training: [491/527] Processing volume...\n",
      "validation step in training epoch 3\n",
      "aorta dissection not manually set, use the value in csv file\n",
      "original image shape: torch.Size([1, 1, 512, 512, 89])\n",
      "inference val set from 10 to 10 batch\n",
      "validation: [1/2] Processing volume...\n",
      "patient ID: 1PC078\n",
      "input volume shape: torch.Size([1, 512, 512, 89])\n",
      "target volume shape: torch.Size([1, 512, 512, 89])\n",
      "ad: tensor(0)\n",
      "modality: tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:42<00:00, 11.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: [2/2] Processing volume...\n",
      "patient ID: 42025705_4\n",
      "input volume shape: torch.Size([1, 512, 512, 39])\n",
      "target volume shape: torch.Size([1, 512, 512, 39])\n",
      "ad: tensor(0)\n",
      "modality: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: [492/527] Processing volume...\n",
      "training: [493/527] Processing volume...\n",
      "training: [494/527] Processing volume...\n",
      "training: [495/527] Processing volume...\n",
      "training: [496/527] Processing volume...\n",
      "training: [497/527] Processing volume...\n",
      "training: [498/527] Processing volume...\n",
      "training: [499/527] Processing volume...\n",
      "training: [500/527] Processing volume...\n",
      "training: [501/527] Processing volume...\n",
      "training: [502/527] Processing volume...\n",
      "training: [503/527] Processing volume...\n",
      "training: [504/527] Processing volume...\n",
      "training: [505/527] Processing volume...\n",
      "training: [506/527] Processing volume...\n",
      "training: [507/527] Processing volume...\n",
      "training: [508/527] Processing volume...\n",
      "training: [509/527] Processing volume...\n",
      "validation step in training epoch 3\n",
      "aorta dissection not manually set, use the value in csv file\n",
      "original image shape: torch.Size([1, 1, 512, 512, 89])\n",
      "inference val set from 10 to 10 batch\n",
      "validation: [1/2] Processing volume...\n",
      "patient ID: 1PC078\n",
      "input volume shape: torch.Size([1, 512, 512, 89])\n",
      "target volume shape: torch.Size([1, 512, 512, 89])\n",
      "ad: tensor(0)\n",
      "modality: tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:42<00:00, 11.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: [2/2] Processing volume...\n",
      "patient ID: 42025705_4\n",
      "input volume shape: torch.Size([1, 512, 512, 39])\n",
      "target volume shape: torch.Size([1, 512, 512, 39])\n",
      "ad: tensor(0)\n",
      "modality: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:42<00:00, 11.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: [510/527] Processing volume...\n",
      "training: [511/527] Processing volume...\n",
      "training: [512/527] Processing volume...\n",
      "training: [513/527] Processing volume...\n",
      "training: [514/527] Processing volume...\n",
      "training: [515/527] Processing volume...\n",
      "training: [516/527] Processing volume...\n",
      "training: [517/527] Processing volume...\n",
      "training: [518/527] Processing volume...\n",
      "training: [519/527] Processing volume...\n",
      "training: [520/527] Processing volume...\n",
      "training: [521/527] Processing volume...\n",
      "training: [522/527] Processing volume...\n",
      "training: [523/527] Processing volume...\n",
      "training: [524/527] Processing volume...\n",
      "training: [525/527] Processing volume...\n",
      "training: [526/527] Processing volume...\n",
      "training: [527/527] Processing volume...\n",
      "validation step in training epoch 3\n",
      "aorta dissection not manually set, use the value in csv file\n",
      "original image shape: torch.Size([1, 1, 512, 512, 89])\n",
      "inference val set from 10 to 10 batch\n",
      "validation: [1/2] Processing volume...\n",
      "patient ID: 1PC078\n",
      "input volume shape: torch.Size([1, 512, 512, 89])\n",
      "target volume shape: torch.Size([1, 512, 512, 89])\n",
      "ad: tensor(0)\n",
      "modality: tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:42<00:00, 11.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: [2/2] Processing volume...\n",
      "patient ID: 42025705_4\n",
      "input volume shape: torch.Size([1, 512, 512, 39])\n",
      "target volume shape: torch.Size([1, 512, 512, 39])\n",
      "ad: tensor(0)\n",
      "modality: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:42<00:00, 11.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation step in training epoch 3\n",
      "aorta dissection not manually set, use the value in csv file\n",
      "original image shape: torch.Size([1, 1, 512, 512, 89])\n",
      "inference val set from 10 to 10 batch\n",
      "validation: [1/2] Processing volume...\n",
      "patient ID: 1PC078\n",
      "input volume shape: torch.Size([1, 512, 512, 89])\n",
      "target volume shape: torch.Size([1, 512, 512, 89])\n",
      "ad: tensor(0)\n",
      "modality: tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: [2/2] Processing volume...\n",
      "patient ID: 42025705_4\n",
      "input volume shape: torch.Size([1, 512, 512, 39])\n",
      "target volume shape: torch.Size([1, 512, 512, 39])\n",
      "ad: tensor(0)\n",
      "modality: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:42<00:00, 11.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss updated, value:  1.083684075441385\n",
      "original image shape: torch.Size([1, 1, 512, 512, 149])\n",
      "training: [1/527] Processing volume...\n",
      "training: [2/527] Processing volume...\n",
      "training: [3/527] Processing volume...\n",
      "training: [4/527] Processing volume...\n",
      "training: [5/527] Processing volume...\n",
      "training: [6/527] Processing volume...\n",
      "training: [7/527] Processing volume...\n",
      "training: [8/527] Processing volume...\n",
      "training: [9/527] Processing volume...\n",
      "training: [10/527] Processing volume...\n",
      "training: [11/527] Processing volume...\n",
      "training: [12/527] Processing volume...\n",
      "training: [13/527] Processing volume...\n",
      "training: [14/527] Processing volume...\n",
      "training: [15/527] Processing volume...\n",
      "training: [16/527] Processing volume...\n",
      "training: [17/527] Processing volume...\n",
      "training: [18/527] Processing volume...\n",
      "training: [19/527] Processing volume...\n",
      "training: [20/527] Processing volume...\n",
      "training: [21/527] Processing volume...\n",
      "training: [22/527] Processing volume...\n",
      "training: [23/527] Processing volume...\n",
      "training: [24/527] Processing volume...\n",
      "training: [25/527] Processing volume...\n",
      "training: [26/527] Processing volume...\n",
      "training: [27/527] Processing volume...\n",
      "training: [28/527] Processing volume...\n",
      "training: [29/527] Processing volume...\n",
      "training: [30/527] Processing volume...\n",
      "training: [31/527] Processing volume...\n",
      "training: [32/527] Processing volume...\n",
      "training: [33/527] Processing volume...\n",
      "validation step in training epoch 4\n",
      "aorta dissection not manually set, use the value in csv file\n",
      "original image shape: torch.Size([1, 1, 512, 512, 89])\n",
      "inference val set from 10 to 10 batch\n",
      "validation: [1/2] Processing volume...\n",
      "patient ID: 1PC078\n",
      "input volume shape: torch.Size([1, 512, 512, 89])\n",
      "target volume shape: torch.Size([1, 512, 512, 89])\n",
      "ad: tensor(0)\n",
      "modality: tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:42<00:00, 11.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: [2/2] Processing volume...\n",
      "patient ID: 42025705_4\n",
      "input volume shape: torch.Size([1, 512, 512, 39])\n",
      "target volume shape: torch.Size([1, 512, 512, 39])\n",
      "ad: tensor(0)\n",
      "modality: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: [34/527] Processing volume...\n",
      "training: [35/527] Processing volume...\n",
      "training: [36/527] Processing volume...\n",
      "training: [37/527] Processing volume...\n",
      "training: [38/527] Processing volume...\n",
      "training: [39/527] Processing volume...\n",
      "training: [40/527] Processing volume...\n",
      "training: [41/527] Processing volume...\n",
      "training: [42/527] Processing volume...\n",
      "training: [43/527] Processing volume...\n",
      "training: [44/527] Processing volume...\n",
      "training: [45/527] Processing volume...\n",
      "training: [46/527] Processing volume...\n",
      "training: [47/527] Processing volume...\n",
      "training: [48/527] Processing volume...\n",
      "training: [49/527] Processing volume...\n",
      "training: [50/527] Processing volume...\n",
      "training: [51/527] Processing volume...\n",
      "training: [52/527] Processing volume...\n",
      "training: [53/527] Processing volume...\n",
      "training: [54/527] Processing volume...\n",
      "training: [55/527] Processing volume...\n",
      "training: [56/527] Processing volume...\n",
      "training: [57/527] Processing volume...\n",
      "training: [58/527] Processing volume...\n",
      "training: [59/527] Processing volume...\n",
      "training: [60/527] Processing volume...\n",
      "training: [61/527] Processing volume...\n",
      "training: [62/527] Processing volume...\n",
      "training: [63/527] Processing volume...\n",
      "training: [64/527] Processing volume...\n",
      "training: [65/527] Processing volume...\n",
      "validation step in training epoch 4\n",
      "aorta dissection not manually set, use the value in csv file\n",
      "original image shape: torch.Size([1, 1, 512, 512, 89])\n",
      "inference val set from 10 to 10 batch\n",
      "validation: [1/2] Processing volume...\n",
      "patient ID: 1PC078\n",
      "input volume shape: torch.Size([1, 512, 512, 89])\n",
      "target volume shape: torch.Size([1, 512, 512, 89])\n",
      "ad: tensor(0)\n",
      "modality: tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: [2/2] Processing volume...\n",
      "patient ID: 42025705_4\n",
      "input volume shape: torch.Size([1, 512, 512, 39])\n",
      "target volume shape: torch.Size([1, 512, 512, 39])\n",
      "ad: tensor(0)\n",
      "modality: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: [66/527] Processing volume...\n",
      "training: [67/527] Processing volume...\n",
      "training: [68/527] Processing volume...\n",
      "training: [69/527] Processing volume...\n",
      "training: [70/527] Processing volume...\n",
      "training: [71/527] Processing volume...\n",
      "training: [72/527] Processing volume...\n",
      "training: [73/527] Processing volume...\n",
      "training: [74/527] Processing volume...\n",
      "training: [75/527] Processing volume...\n",
      "training: [76/527] Processing volume...\n",
      "training: [77/527] Processing volume...\n",
      "training: [78/527] Processing volume...\n",
      "training: [79/527] Processing volume...\n",
      "training: [80/527] Processing volume...\n",
      "training: [81/527] Processing volume...\n",
      "training: [82/527] Processing volume...\n",
      "training: [83/527] Processing volume...\n",
      "training: [84/527] Processing volume...\n",
      "training: [85/527] Processing volume...\n",
      "training: [86/527] Processing volume...\n",
      "training: [87/527] Processing volume...\n",
      "training: [88/527] Processing volume...\n",
      "training: [89/527] Processing volume...\n",
      "training: [90/527] Processing volume...\n",
      "training: [91/527] Processing volume...\n",
      "training: [92/527] Processing volume...\n",
      "training: [93/527] Processing volume...\n",
      "training: [94/527] Processing volume...\n",
      "training: [95/527] Processing volume...\n",
      "training: [96/527] Processing volume...\n",
      "training: [97/527] Processing volume...\n",
      "training: [98/527] Processing volume...\n",
      "training: [99/527] Processing volume...\n",
      "training: [100/527] Processing volume...\n",
      "validation step in training epoch 4\n",
      "aorta dissection not manually set, use the value in csv file\n",
      "original image shape: torch.Size([1, 1, 512, 512, 89])\n",
      "inference val set from 10 to 10 batch\n",
      "validation: [1/2] Processing volume...\n",
      "patient ID: 1PC078\n",
      "input volume shape: torch.Size([1, 512, 512, 89])\n",
      "target volume shape: torch.Size([1, 512, 512, 89])\n",
      "ad: tensor(0)\n",
      "modality: tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: [2/2] Processing volume...\n",
      "patient ID: 42025705_4\n",
      "input volume shape: torch.Size([1, 512, 512, 39])\n",
      "target volume shape: torch.Size([1, 512, 512, 39])\n",
      "ad: tensor(0)\n",
      "modality: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: [101/527] Processing volume...\n",
      "training: [102/527] Processing volume...\n",
      "training: [103/527] Processing volume...\n",
      "training: [104/527] Processing volume...\n",
      "training: [105/527] Processing volume...\n",
      "training: [106/527] Processing volume...\n",
      "training: [107/527] Processing volume...\n",
      "training: [108/527] Processing volume...\n",
      "training: [109/527] Processing volume...\n",
      "training: [110/527] Processing volume...\n",
      "training: [111/527] Processing volume...\n",
      "training: [112/527] Processing volume...\n",
      "training: [113/527] Processing volume...\n",
      "training: [114/527] Processing volume...\n",
      "training: [115/527] Processing volume...\n",
      "training: [116/527] Processing volume...\n",
      "training: [117/527] Processing volume...\n",
      "training: [118/527] Processing volume...\n",
      "training: [119/527] Processing volume...\n",
      "training: [120/527] Processing volume...\n",
      "training: [121/527] Processing volume...\n",
      "training: [122/527] Processing volume...\n",
      "training: [123/527] Processing volume...\n",
      "training: [124/527] Processing volume...\n",
      "training: [125/527] Processing volume...\n",
      "training: [126/527] Processing volume...\n",
      "training: [127/527] Processing volume...\n",
      "training: [128/527] Processing volume...\n",
      "training: [129/527] Processing volume...\n",
      "training: [130/527] Processing volume...\n",
      "training: [131/527] Processing volume...\n",
      "training: [132/527] Processing volume...\n",
      "training: [133/527] Processing volume...\n",
      "training: [134/527] Processing volume...\n",
      "validation step in training epoch 4\n",
      "aorta dissection not manually set, use the value in csv file\n",
      "original image shape: torch.Size([1, 1, 512, 512, 89])\n",
      "inference val set from 10 to 10 batch\n",
      "validation: [1/2] Processing volume...\n",
      "patient ID: 1PC078\n",
      "input volume shape: torch.Size([1, 512, 512, 89])\n",
      "target volume shape: torch.Size([1, 512, 512, 89])\n",
      "ad: tensor(0)\n",
      "modality: tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: [2/2] Processing volume...\n",
      "patient ID: 42025705_4\n",
      "input volume shape: torch.Size([1, 512, 512, 39])\n",
      "target volume shape: torch.Size([1, 512, 512, 39])\n",
      "ad: tensor(0)\n",
      "modality: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: [135/527] Processing volume...\n",
      "training: [136/527] Processing volume...\n",
      "training: [137/527] Processing volume...\n",
      "training: [138/527] Processing volume...\n",
      "training: [139/527] Processing volume...\n",
      "training: [140/527] Processing volume...\n",
      "training: [141/527] Processing volume...\n",
      "training: [142/527] Processing volume...\n",
      "training: [143/527] Processing volume...\n",
      "training: [144/527] Processing volume...\n",
      "training: [145/527] Processing volume...\n",
      "training: [146/527] Processing volume...\n",
      "training: [147/527] Processing volume...\n",
      "training: [148/527] Processing volume...\n",
      "training: [149/527] Processing volume...\n",
      "training: [150/527] Processing volume...\n",
      "training: [151/527] Processing volume...\n",
      "training: [152/527] Processing volume...\n",
      "training: [153/527] Processing volume...\n",
      "training: [154/527] Processing volume...\n",
      "training: [155/527] Processing volume...\n",
      "training: [156/527] Processing volume...\n",
      "training: [157/527] Processing volume...\n",
      "training: [158/527] Processing volume...\n",
      "training: [159/527] Processing volume...\n",
      "training: [160/527] Processing volume...\n",
      "training: [161/527] Processing volume...\n",
      "training: [162/527] Processing volume...\n",
      "training: [163/527] Processing volume...\n",
      "training: [164/527] Processing volume...\n",
      "training: [165/527] Processing volume...\n",
      "training: [166/527] Processing volume...\n",
      "validation step in training epoch 4\n",
      "aorta dissection not manually set, use the value in csv file\n",
      "original image shape: torch.Size([1, 1, 512, 512, 89])\n",
      "inference val set from 10 to 10 batch\n",
      "validation: [1/2] Processing volume...\n",
      "patient ID: 1PC078\n",
      "input volume shape: torch.Size([1, 512, 512, 89])\n",
      "target volume shape: torch.Size([1, 512, 512, 89])\n",
      "ad: tensor(0)\n",
      "modality: tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: [2/2] Processing volume...\n",
      "patient ID: 42025705_4\n",
      "input volume shape: torch.Size([1, 512, 512, 39])\n",
      "target volume shape: torch.Size([1, 512, 512, 39])\n",
      "ad: tensor(0)\n",
      "modality: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:41<00:00, 11.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: [167/527] Processing volume...\n",
      "training: [168/527] Processing volume...\n",
      "training: [169/527] Processing volume...\n",
      "training: [170/527] Processing volume...\n",
      "training: [171/527] Processing volume...\n",
      "training: [172/527] Processing volume...\n",
      "training: [173/527] Processing volume...\n",
      "training: [174/527] Processing volume...\n",
      "training: [175/527] Processing volume...\n",
      "training: [176/527] Processing volume...\n",
      "training: [177/527] Processing volume...\n",
      "training: [178/527] Processing volume...\n",
      "training: [179/527] Processing volume...\n",
      "training: [180/527] Processing volume...\n",
      "training: [181/527] Processing volume...\n",
      "training: [182/527] Processing volume...\n",
      "training: [183/527] Processing volume...\n",
      "training: [184/527] Processing volume...\n",
      "training: [185/527] Processing volume...\n",
      "training: [186/527] Processing volume...\n",
      "training: [187/527] Processing volume...\n",
      "training: [188/527] Processing volume...\n",
      "training: [189/527] Processing volume...\n",
      "training: [190/527] Processing volume...\n",
      "training: [191/527] Processing volume...\n",
      "training: [192/527] Processing volume...\n",
      "training: [193/527] Processing volume...\n",
      "training: [194/527] Processing volume...\n",
      "training: [195/527] Processing volume...\n",
      "training: [196/527] Processing volume...\n",
      "training: [197/527] Processing volume...\n",
      "validation step in training epoch 4\n",
      "aorta dissection not manually set, use the value in csv file\n",
      "original image shape: torch.Size([1, 1, 512, 512, 89])\n",
      "inference val set from 10 to 10 batch\n",
      "validation: [1/2] Processing volume...\n",
      "patient ID: 1PC078\n",
      "input volume shape: torch.Size([1, 512, 512, 89])\n",
      "target volume shape: torch.Size([1, 512, 512, 89])\n",
      "ad: tensor(0)\n",
      "modality: tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:42<00:00, 11.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: [2/2] Processing volume...\n",
      "patient ID: 42025705_4\n",
      "input volume shape: torch.Size([1, 512, 512, 39])\n",
      "target volume shape: torch.Size([1, 512, 512, 39])\n",
      "ad: tensor(0)\n",
      "modality: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:42<00:00, 11.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: [198/527] Processing volume...\n",
      "training: [199/527] Processing volume...\n",
      "training: [200/527] Processing volume...\n",
      "training: [201/527] Processing volume...\n",
      "training: [202/527] Processing volume...\n",
      "training: [203/527] Processing volume...\n",
      "training: [204/527] Processing volume...\n",
      "training: [205/527] Processing volume...\n",
      "training: [206/527] Processing volume...\n",
      "training: [207/527] Processing volume...\n",
      "training: [208/527] Processing volume...\n",
      "training: [209/527] Processing volume...\n",
      "training: [210/527] Processing volume...\n",
      "training: [211/527] Processing volume...\n",
      "training: [212/527] Processing volume...\n",
      "training: [213/527] Processing volume...\n",
      "training: [214/527] Processing volume...\n",
      "training: [215/527] Processing volume...\n",
      "training: [216/527] Processing volume...\n",
      "training: [217/527] Processing volume...\n",
      "training: [218/527] Processing volume...\n",
      "training: [219/527] Processing volume...\n",
      "training: [220/527] Processing volume...\n",
      "training: [221/527] Processing volume...\n",
      "training: [222/527] Processing volume...\n",
      "training: [223/527] Processing volume...\n",
      "training: [224/527] Processing volume...\n",
      "training: [225/527] Processing volume...\n",
      "training: [226/527] Processing volume...\n",
      "training: [227/527] Processing volume...\n",
      "validation step in training epoch 4\n",
      "aorta dissection not manually set, use the value in csv file\n",
      "original image shape: torch.Size([1, 1, 512, 512, 89])\n",
      "inference val set from 10 to 10 batch\n",
      "validation: [1/2] Processing volume...\n",
      "patient ID: 1PC078\n",
      "input volume shape: torch.Size([1, 512, 512, 89])\n",
      "target volume shape: torch.Size([1, 512, 512, 89])\n",
      "ad: tensor(0)\n",
      "modality: tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:42<00:00, 11.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: [2/2] Processing volume...\n",
      "patient ID: 42025705_4\n",
      "input volume shape: torch.Size([1, 512, 512, 39])\n",
      "target volume shape: torch.Size([1, 512, 512, 39])\n",
      "ad: tensor(0)\n",
      "modality: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [00:42<00:00, 11.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: [228/527] Processing volume...\n",
      "training: [229/527] Processing volume...\n",
      "training: [230/527] Processing volume...\n",
      "training: [231/527] Processing volume...\n",
      "training: [232/527] Processing volume...\n",
      "training: [233/527] Processing volume...\n",
      "training: [234/527] Processing volume...\n",
      "training: [235/527] Processing volume...\n",
      "training: [236/527] Processing volume...\n",
      "training: [237/527] Processing volume...\n",
      "training: [238/527] Processing volume...\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\zy7\\.conda\\envs\\torch\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\zy7\\AppData\\Local\\Temp\\4\\ipykernel_28388\\3555883077.py\", line 2, in <module>\n",
      "    train.run(config='tutorial2_config_prior.yaml', dataset_name = 'multimodal_prior_csv')\n",
      "  File \"e:\\Projects\\yang_proj\\SynthRad_GAN\\synthrad_conversion\\train.py\", line 166, in run\n",
      "    return reconstructed_volume, count_volume\n",
      "  File \"e:\\Projects\\yang_proj\\SynthRad_GAN\\synthrad_conversion\\networks\\launch_model.py\", line 15, in launch_model\n",
      "    runner.train()\n",
      "  File \"e:\\Projects\\yang_proj\\SynthRad_GAN\\synthrad_conversion\\networks\\ddpm\\ddpm_mri2ct.py\", line 63, in train\n",
      "    def __init__(self, opt, paths, train_loader, val_loader, train_patient_IDs, test_patient_IDs):\n",
      "  File \"e:\\Projects\\yang_proj\\SynthRad_GAN\\synthrad_conversion\\networks\\ddpm\\ddpm_mri2ct.py\", line 788, in train\n",
      "  File \"c:\\Users\\zy7\\.conda\\envs\\torch\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py\", line 341, in step\n",
      "    retval = self._maybe_opt_step(optimizer, optimizer_state, *args, **kwargs)\n",
      "  File \"c:\\Users\\zy7\\.conda\\envs\\torch\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py\", line 287, in _maybe_opt_step\n",
      "    if not sum(v.item() for v in optimizer_state[\"found_inf_per_device\"].values()):\n",
      "  File \"c:\\Users\\zy7\\.conda\\envs\\torch\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py\", line 287, in <genexpr>\n",
      "    if not sum(v.item() for v in optimizer_state[\"found_inf_per_device\"].values()):\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\zy7\\.conda\\envs\\torch\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2105, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"c:\\Users\\zy7\\.conda\\envs\\torch\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1396, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"c:\\Users\\zy7\\.conda\\envs\\torch\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1287, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"c:\\Users\\zy7\\.conda\\envs\\torch\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1140, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"c:\\Users\\zy7\\.conda\\envs\\torch\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1055, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"c:\\Users\\zy7\\.conda\\envs\\torch\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 955, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"c:\\Users\\zy7\\.conda\\envs\\torch\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 778, in lines\n",
      "    return self._sd.lines\n",
      "  File \"c:\\Users\\zy7\\.conda\\envs\\torch\\lib\\site-packages\\stack_data\\utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\Users\\zy7\\.conda\\envs\\torch\\lib\\site-packages\\stack_data\\core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"c:\\Users\\zy7\\.conda\\envs\\torch\\lib\\site-packages\\stack_data\\utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\Users\\zy7\\.conda\\envs\\torch\\lib\\site-packages\\stack_data\\core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"c:\\Users\\zy7\\.conda\\envs\\torch\\lib\\site-packages\\stack_data\\utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\Users\\zy7\\.conda\\envs\\torch\\lib\\site-packages\\stack_data\\core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "  File \"c:\\Users\\zy7\\.conda\\envs\\torch\\lib\\site-packages\\executing\\executing.py\", line 116, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "from synthrad_conversion import train\n",
    "train.run(config='tutorial2_config_prior.yaml', dataset_name = 'multimodal_prior_csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
